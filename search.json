[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Aarushi Nema",
    "section": "",
    "text": "Building a Customer Support Agent Using Amazon BedRock AgentCore\n\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\nSep 17, 2025\n\n\nAarushi Nema\n\n\n\n\n\n\n\n\n\n\n\n\nBackground:\n\n\n\nMachine Learning Projects\n\n\n\n\n\n\n\n\n\nDec 31, 2024\n\n\nAarushi Nema\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\nnews\n\ncode\n\nanalysis\n\n\n\n\n\n\n\n\n\nDec 31, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nRoundUp: Finance Tracking App\n\n\n\nDesign Portfolio\n\n\n\n\n\n\n\n\n\nFeb 22, 2023\n\n\nAarushi Nema\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Aarushi Nema",
    "section": "",
    "text": "Building a Customer Support Agent Using Amazon BedRock AgentCore\n\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\nSep 17, 2025\n\n\nAarushi Nema\n\n\n\n\n\n\n\n\n\n\n\n\nBackground:\n\n\n\nMachine Learning Projects\n\n\n\n\n\n\n\n\n\nDec 31, 2024\n\n\nAarushi Nema\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\nnews\n\ncode\n\nanalysis\n\n\n\n\n\n\n\n\n\nDec 31, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nRoundUp: Finance Tracking App\n\n\n\nDesign Portfolio\n\n\n\n\n\n\n\n\n\nFeb 22, 2023\n\n\nAarushi Nema\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index_old.html#about-me",
    "href": "index_old.html#about-me",
    "title": "Aarushi Nema",
    "section": "About me",
    "text": "About me\nHello, World!  I‚Äôm Aarushi, a final year student @ Nanyang Technological University, Singapore where I am majoring in Data Science and Artificial Intelligence. I am passionate about leveraging Data and AI to solve challenging problems, create meaningful value, and design solutions that leave a lasting impact. I also have a keen interest in creating intuitive UI/UX designs, where functionality meets creativity. I throuoghly emjoy working at the cusp of people and technology.\nMy interest in tech started back in 2012 when I watched a host of sci-fi movies. Fast-forward to today, and I‚Äôve had the privilege of working at a semiconductor company, an automobile company and a student-led IT committee.\nIn my free time, I enjoy drawing üé®, cooking üë©‚Äçüç≥, and working out üèãÔ∏è‚Äç‚ôÄÔ∏è."
  },
  {
    "objectID": "index_old.html#work-experience",
    "href": "index_old.html#work-experience",
    "title": "Aarushi Nema",
    "section": " Work Experience:",
    "text": "Work Experience:\n\n  Download Resume (PDF)\n\n\n\n\n  \n  \n    \n    \n      Data Platform Intern ‚Äî Hyundai Motor Group Innovation Centre Singapore\n      May 2024 ‚Äî Aug 2024\n      \n        Engineered migration pipelines (PostgreSQL/Tibero ‚Üí Hadoop) with Python, PySpark, Airflow.\n        Built REST APIs (Flask + PySpark) for lake querying across formats.\n        Implemented cross-DB sync into PostgreSQL using PySpark.\n      \n      \n        PythonPySparkAirflow\n      \n    \n  \n\n  \n  \n    \n    \n      Software Development (Data App) Intern ‚Äî Infineon Technologies\n      May 2023 ‚Äî Dec 2023\n        \n          Automated ETL to SQL (with Jenkins); built email notifier.\n          Centralized RPA (UiPath + Python) ‚Üí 90% less manual effort.\n          Confluence chatbot (React, Flask, SQL) to speed tool lookup.\n        \n      \n        RPAJenkinsFlask"
  },
  {
    "objectID": "index_old.html#tools-of-the-trade",
    "href": "index_old.html#tools-of-the-trade",
    "title": "Aarushi Nema",
    "section": " Tools of the Trade:",
    "text": "Tools of the Trade:"
  },
  {
    "objectID": "index_old.html#contact",
    "href": "index_old.html#contact",
    "title": "Aarushi Nema",
    "section": " Contact",
    "text": "Contact\nWould like to have a chat? Click here to send me an e-mail.\nI am also happy to connect on different social and professional platforms. Click the badges below to see my profile."
  },
  {
    "objectID": "code_files/aws_agentcore/lab-02-agentcore-memory.html",
    "href": "code_files/aws_agentcore/lab-02-agentcore-memory.html",
    "title": "Lab 2: Personalize our agent by adding memory",
    "section": "",
    "text": "In Lab 1, you built a Customer Support Agent that worked well for a single user in a local session. However, real-world customer support needs to scale beyond a single user running in a local environment.\nWhen we run an Agent in Production, we‚Äôll need: - Multi-User Support: Handle thousands of customers simultaneously - Persistent Storage: Save conversations beyond session lifecycle - Long-Term Learning: Extract customer preferences and behavioral patterns - Cross-Session Continuity: Remember customers across different interactions\nWorkshop Progress: - Lab 1 (Done): Create Agent Prototype - Build a functional customer support agent - Lab 2 (Current): Enhance with Memory - Add conversation context and personalization - Lab 3: Scale with Gateway & Identity - Share tools across agents securely - Lab 4: Deploy to Production - Use AgentCore Runtime with observability - Lab 5: Build User Interface - Create a customer-facing application\nIn this lab, you‚Äôll add the missing persistence and learning layer that transforms your Goldfish-Agent (forgets the conversation in seconds) into an smart personalized Assistant.\nMemory is a critical component of intelligence. While Large Language Models (LLMs) have impressive capabilities, they lack persistent memory across conversations. Amazon Bedrock AgentCore Memory addresses this limitation by providing a managed service that enables AI agents to maintain context over time, remember important facts, and deliver consistent, personalized experiences.\nAgentCore Memory operates on two levels: - Short-Term Memory: Immediate conversation context and session-based information that provides continuity within a single interaction or closely related sessions. - Long-Term Memory: Persistent information extracted and stored across multiple conversations, including facts, preferences, and summaries that enable personalized experiences over time."
  },
  {
    "objectID": "code_files/aws_agentcore/lab-02-agentcore-memory.html#step-3-seed-previous-customer-interactions",
    "href": "code_files/aws_agentcore/lab-02-agentcore-memory.html#step-3-seed-previous-customer-interactions",
    "title": "Lab 2: Personalize our agent by adding memory",
    "section": "Step 3: Seed previous customer interactions",
    "text": "Step 3: Seed previous customer interactions\nWhy are we seeding memory?\nIn production, agents accumulate memory naturally through customer interactions. However, for this lab, we‚Äôre seeding historical conversations to demonstrate how Long-Term Memory (LTM) works without waiting for real conversations.\nHow memory processing works: 1. create_event stores interactions in Short-Term Memory (STM) instantly 2. STM is asynchronously processed by Long-Term Memory strategies 3. LTM extracts patterns, preferences, and facts for future retrieval\nLet‚Äôs seed some customer history to see this in action:\n\n# List existing memory resources\nfor memory in memory_client.list_memories():\n    print(f\"Memory Arn: {memory.get('arn')}\")\n    print(f\"Memory ID: {memory.get('id')}\")\n    print(\"--------------------------------------------------------------------\")\n\n# Seed with previous customer interactions\nCUSTOMER_ID = \"customer_001\"\n\nprevious_interactions = [\n    (\"I'm having issues with my MacBook Pro overheating during video editing.\",\"USER\"),\n    (\"I can help with that thermal issue. For video editing workloads, let's check your Activity Monitor and adjust performance settings. Your MacBook Pro order #MB-78432 is still under warranty.\", \"ASSISTANT\"),\n    (\"What's the return policy on gaming headphones? I need low latency for competitive FPS games\", \"USER\"),\n    (\"For gaming headphones, you have 30 days to return. Since you're into competitive FPS, I'd recommend checking the audio latency specs - most gaming models have &lt;40ms latency.\", \"ASSISTANT\"),\n    (\"I need a laptop under $1200 for programming. Prefer 16GB RAM minimum and good Linux compatibility. I like ThinkPad models.\", \"USER\"),\n    (\"Perfect! For development work, I'd suggest looking at our ThinkPad E series or Dell XPS models. Both have excellent Linux support and 16GB RAM options within your budget.\", \"ASSISTANT\"),\n]\n\n# Save previous interactions\nif memory_id:\n    try:\n        memory_client.create_event(\n            memory_id=memory_id,\n            actor_id=CUSTOMER_ID,\n            session_id=\"previous_session\",\n            messages=previous_interactions\n        )\n        print(\"‚úÖ Seeded customer history successfully\")\n        print(\"üìù Interactions saved to Short-Term Memory\")\n        print(\"‚è≥ Long-Term Memory processing will begin automatically...\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Error seeding history: {e}\")\n\nMemory Arn: arn:aws:bedrock-agentcore:us-west-2:900569417635:memory/CustomerSupportMemory-cGl9C845Vd\nMemory ID: CustomerSupportMemory-cGl9C845Vd\n--------------------------------------------------------------------\n‚úÖ Seeded customer history successfully\nüìù Interactions saved to Short-Term Memory\n‚è≥ Long-Term Memory processing will begin automatically...\n\n\n\nUnderstanding Memory Processing\nAfter creating events with create_event, AgentCore Memory processes the data in two stages:\n\nImmediate: Messages stored in Short-Term Memory (STM)\nAsynchronous: STM processed into Long-Term Memory (LTM) strategies\n\nLTM processing typically takes 20-30 seconds as the system: - Analyzes conversation patterns - Extracts customer preferences and behaviors - Creates semantic embeddings for factual information - Organizes memories by namespace for efficient retrieval\nLet‚Äôs check if our Long-Term Memory processing is complete by retrieving customer preferences:\n\nimport time\n\n# Wait for Long-Term Memory processing to complete\nprint(\"üîç Checking for processed Long-Term Memories...\")\nretries = 0\nmax_retries = 6  # 1 minute wait\n\nwhile retries &lt; max_retries:\n    memories = memory_client.retrieve_memories(\n        memory_id=memory_id,\n        namespace=f\"support/customer/{CUSTOMER_ID}/preferences\",\n        query=\"can you summarize the support issue\"\n    )\n    \n    if memories:\n        print(f\"‚úÖ Found {len(memories)} preference memories after {retries * 10} seconds!\")\n        break\n    \n    retries += 1\n    if retries &lt; max_retries:\n        print(f\"‚è≥ Still processing... waiting 10 more seconds (attempt {retries}/{max_retries})\")\n        time.sleep(10)\n    else:\n        print(\"‚ö†Ô∏è Memory processing is taking longer than expected. This can happen with overloading..\")\n        break\n\nprint(\"üéØ AgentCore Memory automatically extracted these customer preferences from our seeded conversations:\")\nprint(\"=\" * 80)\n\nfor i, memory in enumerate(memories, 1):\n    if isinstance(memory, dict):\n        content = memory.get('content', {})\n        if isinstance(content, dict):\n            text = content.get('text', '')\n            print(f\"  {i}. {text}\")\n\nüîç Checking for processed Long-Term Memories...\n‚è≥ Still processing... waiting 10 more seconds (attempt 1/6)\n‚è≥ Still processing... waiting 10 more seconds (attempt 2/6)\n‚è≥ Still processing... waiting 10 more seconds (attempt 3/6)\n‚è≥ Still processing... waiting 10 more seconds (attempt 4/6)\n‚úÖ Found 3 preference memories after 40 seconds!\nüéØ AgentCore Memory automatically extracted these customer preferences from our seeded conversations:\n================================================================================\n  1. {\"context\":\"User reported technical issue with MacBook Pro during video editing\",\"preference\":\"Uses MacBook Pro for video editing, experiencing performance/thermal challenges\",\"categories\":[\"technology\",\"computing\",\"video editing\",\"hardware\"]}\n  2. {\"context\":\"User inquired about gaming headphones with specific performance requirement\",\"preference\":\"Needs low latency gaming headphones for competitive FPS games\",\"categories\":[\"gaming\",\"audio equipment\",\"technology\"]}\n  3. {\"context\":\"User explicitly mentioned requirements for laptop purchase for programming\",\"preference\":\"Wants laptop under $1200, with 16GB RAM minimum, good Linux compatibility, preferring ThinkPad models\",\"categories\":[\"technology\",\"computing\",\"laptops\",\"programming\"]}\n\n\n\n\nExploring Semantic Memory\nSemantic memory stores factual information from conversations using vector embeddings. This enables similarity-based retrieval of relevant facts and context.\n\nimport time\n# Retrieve semantic memories (factual information)\nwhile True:\n    semantic_memories = memory_client.retrieve_memories(\n        memory_id=memory_id,\n        namespace=f\"support/customer/{CUSTOMER_ID}/semantic\",\n        query=\"information on the technical support issue\"\n    )\n    print(\"üß† AgentCore Memory identified these factual details from conversations:\")\n    print(\"=\" * 80)\n    if memories:\n        break\n    time.sleep(10)\nfor i, memory in enumerate(semantic_memories, 1):\n    if isinstance(memory, dict):\n        content = memory.get('content', {})\n        if isinstance(content, dict):\n            text = content.get('text', '')\n            print(f\"  {i}. {text}\")\n\nüß† AgentCore Memory identified these factual details from conversations:\n================================================================================\n  1. The user is interested in gaming headphones with low latency for competitive FPS games.\n  2. The user is looking for a laptop under $1200 for programming, with a preference for 16GB RAM and good Linux compatibility.\n  3. The user is experiencing overheating issues with their MacBook Pro during video editing."
  },
  {
    "objectID": "code_files/aws_agentcore/lab-02-agentcore-memory.html#step-3-implement-strands-hooks-to-save-and-retrieve-agent-interactions",
    "href": "code_files/aws_agentcore/lab-02-agentcore-memory.html#step-3-implement-strands-hooks-to-save-and-retrieve-agent-interactions",
    "title": "Lab 2: Personalize our agent by adding memory",
    "section": "Step 3: Implement Strands Hooks to save and retrieve agent interactions",
    "text": "Step 3: Implement Strands Hooks to save and retrieve agent interactions\nNow we‚Äôll integrate AgentCore Memory with our agent using Strands‚Äô hook system. This creates an automatic memory layer that works seamlessly with any agent conversation.\n\nMessageAddedEvent: Triggered when messages are added to the conversation, allowing us to retrieve and inject customer context\nAfterInvocationEvent: Fired after agent responses, enabling automatic storage of interactions to memory\n\nThe hook system ensures memory operations happen automatically without manual intervention, creating a seamless experience where customer context is preserved across conversations.\nTo create the hooks we will extend the HookProvider class:\n\nclass CustomerSupportMemoryHooks(HookProvider):\n    \"\"\"Memory hooks for customer support agent\"\"\"\n\n    def __init__(\n        self, memory_id: str, client: MemoryClient, actor_id: str, session_id: str\n    ):\n        self.memory_id = memory_id\n        self.client = client\n        self.actor_id = actor_id\n        self.session_id = session_id\n        self.namespaces = {\n            i[\"type\"]: i[\"namespaces\"][0]\n            for i in self.client.get_memory_strategies(self.memory_id)\n        }\n\n    def retrieve_customer_context(self, event: MessageAddedEvent):\n        \"\"\"Retrieve customer context before processing support query\"\"\"\n        messages = event.agent.messages\n        if (\n            messages[-1][\"role\"] == \"user\"\n            and \"toolResult\" not in messages[-1][\"content\"][0]\n        ):\n            user_query = messages[-1][\"content\"][0][\"text\"]\n\n            try:\n                all_context = []\n\n                for context_type, namespace in self.namespaces.items():\n                    # *** AGENTCORE MEMORY USAGE *** - Retrieve customer context from each namespace\n                    memories = self.client.retrieve_memories(\n                        memory_id=self.memory_id,\n                        namespace=namespace.format(actorId=self.actor_id),\n                        query=user_query,\n                        top_k=3,\n                    )\n                    # Post-processing: Format memories into context strings\n                    for memory in memories:\n                        if isinstance(memory, dict):\n                            content = memory.get(\"content\", {})\n                            if isinstance(content, dict):\n                                text = content.get(\"text\", \"\").strip()\n                                if text:\n                                    all_context.append(\n                                        f\"[{context_type.upper()}] {text}\"\n                                    )\n\n                # Inject customer context into the query\n                if all_context:\n                    context_text = \"\\n\".join(all_context)\n                    original_text = messages[-1][\"content\"][0][\"text\"]\n                    messages[-1][\"content\"][0][\n                        \"text\"\n                    ] = f\"Customer Context:\\n{context_text}\\n\\n{original_text}\"\n                    logger.info(f\"Retrieved {len(all_context)} customer context items\")\n\n            except Exception as e:\n                logger.error(f\"Failed to retrieve customer context: {e}\")\n\n    def save_support_interaction(self, event: AfterInvocationEvent):\n        \"\"\"Save customer support interaction after agent response\"\"\"\n        try:\n            messages = event.agent.messages\n            if len(messages) &gt;= 2 and messages[-1][\"role\"] == \"assistant\":\n                # Get last customer query and agent response\n                customer_query = None\n                agent_response = None\n\n                for msg in reversed(messages):\n                    if msg[\"role\"] == \"assistant\" and not agent_response:\n                        agent_response = msg[\"content\"][0][\"text\"]\n                    elif (\n                        msg[\"role\"] == \"user\"\n                        and not customer_query\n                        and \"toolResult\" not in msg[\"content\"][0]\n                    ):\n                        customer_query = msg[\"content\"][0][\"text\"]\n                        break\n\n                if customer_query and agent_response:\n                    # *** AGENTCORE MEMORY USAGE *** - Save the support interaction\n                    self.client.create_event(\n                        memory_id=self.memory_id,\n                        actor_id=self.actor_id,\n                        session_id=self.session_id,\n                        messages=[\n                            (customer_query, \"USER\"),\n                            (agent_response, \"ASSISTANT\"),\n                        ],\n                    )\n                    logger.info(\"Saved support interaction to memory\")\n\n        except Exception as e:\n            logger.error(f\"Failed to save support interaction: {e}\")\n\n    def register_hooks(self, registry: HookRegistry) -&gt; None:\n        \"\"\"Register customer support memory hooks\"\"\"\n        registry.add_callback(MessageAddedEvent, self.retrieve_customer_context)\n        registry.add_callback(AfterInvocationEvent, self.save_support_interaction)\n        logger.info(\"Customer support memory hooks registered\")"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-02-agentcore-memory.html#step-4-create-a-customer-support-agent-with-memory",
    "href": "code_files/aws_agentcore/lab-02-agentcore-memory.html#step-4-create-a-customer-support-agent-with-memory",
    "title": "Lab 2: Personalize our agent by adding memory",
    "section": "Step 4: Create a Customer Support Agent with memory",
    "text": "Step 4: Create a Customer Support Agent with memory\nNext, we will implement the Customer Support Agent just as we did in Lab 1, but this time we instantiate the class CustomerSupportMemoryHooks and we pass the memory hook to the agent contructor.\n\nimport uuid\n\nfrom strands import Agent\nfrom strands.models import BedrockModel\n\nfrom lab_helpers.lab1_strands_agent import (\n    SYSTEM_PROMPT,\n    get_return_policy, web_search,\n    get_product_info, get_technical_support, MODEL_ID\n)\n\nSESSION_ID = str(uuid.uuid4())\nmemory_hooks = CustomerSupportMemoryHooks(memory_id, memory_client, CUSTOMER_ID, SESSION_ID)\n\n\n# Initialize the Bedrock model (Anthropic Claude 3.7 Sonnet)\nmodel = BedrockModel(\n    model_id=MODEL_ID,\n    region_name=REGION\n)\n\n# Create the customer support agent with all 5 tools\nagent = Agent(\n    model=model,\n    hooks=[memory_hooks], # Pass Memory Hooks\n    tools=[\n        get_product_info,      # Tool 1: Simple product information lookup\n        get_return_policy,      # Tool 2: Simple return policy lookup\n        web_search,\n        get_technical_support\n    ],\n    system_prompt=SYSTEM_PROMPT\n)"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-02-agentcore-memory.html#step-5-test-personalized-agent",
    "href": "code_files/aws_agentcore/lab-02-agentcore-memory.html#step-5-test-personalized-agent",
    "title": "Lab 2: Personalize our agent by adding memory",
    "section": "Step 5: Test Personalized Agent",
    "text": "Step 5: Test Personalized Agent\nLet‚Äôs test our memory-enhanced agent! Watch how it uses the customer‚Äôs historical preferences to provide personalized recommendations.\nThe agent will automatically: 1. Retrieve relevant customer context from memory 2. Use that context to personalize the response 3. Save this new interaction for future use\n\nfrom IPython.display import display, Markdown\n\nprint(\"üéß Testing headphone recommendation with customer memory...\\n\\n\")\nresponse1 = agent(\"Which headphones would you recommend?\")\n\nüéß Testing headphone recommendation with customer memory...\n\n\nI'd be happy to help you find some gaming headphones with low latency, perfect for competitive FPS games where timing is critical. Let me get some specific information about gaming headphones for you.\nTool #1: get_product_info\nBased on your need for low-latency gaming headphones for competitive FPS games, let me search for some specific recommendations that would work well for your requirements:\nTool #2: web_search\nBased on the information I've gathered, here are my recommendations for gaming headphones that would be ideal for competitive FPS games where low latency is crucial:\n\n### Top Recommendations for Low Latency Gaming Headphones:\n\n1. **SteelSeries Arctis Nova Pro** - Considered a top choice for competitive gaming with excellent multi-device connectivity. The wireless version offers very low latency that's ideal for FPS games.\n\n2. **Turtle Beach Stealth 700 Gen 2** - Specifically mentioned as a next-generation competitive gaming headset with improved audio performance for better game performance.\n\n3. **Headphones with aptX Low Latency Support** - Look for headphones supporting this codec, as it can reduce latency to under 40ms, which experts consider ideal for competitive gaming.\n\n### What to Look For:\n- **Latency under 40ms** - For competitive FPS games, this is considered the benchmark for lag-free audio\n- **Good positional audio** - Critical for accurately locating enemies in FPS games\n- **Comfort** - Important for long gaming sessions\n- **Quality microphone** - For clear communication with teammates\n\n### Connection Type Consideration:\n- **Wired options** generally offer the lowest latency and are most reliable for competitive play\n- **Wireless options** with specialized gaming-focused transmission technology can also perform well\n\nWould you like more specific information about any of these models? Or would you prefer I search for options in a particular price range? I can also provide information about return policies if you'd like to try a pair before fully committing to them.\n\n\n\nprint(\"\\nüíª Testing laptop preference recall...\\n\\n\")\nresponse2 = agent(\"What is my preferred laptop brand and requirements?\")\n\n\nüíª Testing laptop preference recall...\n\n\nBased on your previous interactions, I can see your preferred laptop specifications quite clearly.\n\nYour preferred laptop requirements are:\n- Brand preference: ThinkPad models\n- Budget: Under $1200\n- RAM: Minimum of 16GB\n- Operating system compatibility: Good Linux compatibility\n- Purpose: Programming\n\nThinkPad is definitely your preferred laptop brand, and you're looking for a model that meets these specific requirements for programming work. ThinkPads are known for their excellent Linux compatibility, which aligns perfectly with your preferences.\n\nIs there anything specific about ThinkPad models you'd like to know more about, or would you like me to provide some recommendations for ThinkPad models that meet your requirements for programming? I'd be happy to search for current models that fit your budget and specifications.\n\n\nNotice how the Agent remembers: ‚Ä¢ Your gaming preferences (low latency headphones) ‚Ä¢ Your laptop preferences (ThinkPad, 16GB RAM, Linux compatibility) ‚Ä¢ Your budget constraints ($1200 for laptops) ‚Ä¢ Previous technical issues (MacBook overheating)\nThis is the power of AgentCore Memory - persistent, personalized customer experiences!"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-02-agentcore-memory.html#congratulations",
    "href": "code_files/aws_agentcore/lab-02-agentcore-memory.html#congratulations",
    "title": "Lab 2: Personalize our agent by adding memory",
    "section": "Congratulations! üéâ",
    "text": "Congratulations! üéâ\nYou have successfully completed Lab 2: Add memory to the Customer Support Agent!\n\nWhat You Accomplished:\n\nCreated a serverless managed memory with Amazon Bedrock AgentCore Memory\nImplemented long-term memory to store User-Preferences and Semantic (Factual) information.\nIntegrated AgentCore Memory with the customer support Agent using the hook mechanism provided by Strands Agents\n\n\nNext Up Lab 3 - Scaling with Gateway and Identity ‚Üí"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-02-agentcore-memory.html#resources",
    "href": "code_files/aws_agentcore/lab-02-agentcore-memory.html#resources",
    "title": "Lab 2: Personalize our agent by adding memory",
    "section": "Resources",
    "text": "Resources\n\nAmazon Bedrock Agent Core Memory\nAmazon Bedrock AgentCore Memory Deep Dive blog\nStrands Agents Hooks Documentation"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-04-agentcore-runtime.html",
    "href": "code_files/aws_agentcore/lab-04-agentcore-runtime.html",
    "title": "Lab 4: Deploy to Production - Use AgentCore Runtime with Observability",
    "section": "",
    "text": "Overview\nIn Lab 3 we scaled our Customer Support Agent by centralizing tools through AgentCore Gateway with secure authentication. Now we‚Äôll complete the production journey by deploying our agent to AgentCore Runtime with comprehensive observability. This will transform our prototype into a production-ready system that can handle real-world traffic with full monitoring and automatic scaling.\nAmazon Bedrock AgentCore Runtime is a secure, fully managed runtime that empowers organizations to deploy and scale AI agents in production, regardless of framework, protocol, or model choice. It provides enterprise-grade reliability, automatic scaling, and comprehensive monitoring capabilities.\nWorkshop Journey:\n\nLab 1 (Done): Create Agent Prototype - Built a functional customer support agent\nLab 2 (Done): Enhance with Memory - Added conversation context and personalization\nLab 3 (Done): Scale with Gateway & Identity - Shared tools across agents securely\nLab 4 (Current): Deploy to Production - Used AgentCore Runtime with observability\nLab 5: Build User Interface - Create a customer-facing application\n\n\n\nWhy AgentCore Runtime & Production Deployment Matter\nCurrent State (Lab 1-3): Agent runs locally with centralized tools but faces production challenges:\n\nAgent runs locally in a single session\nNo comprehensive monitoring or debugging capabilities\nCannot handle multiple concurrent users reliably\n\nAfter this lab, we will have a production-ready agent infrastructure with:\n\nServerless auto-scaling to handle variable demand\nComprehensive observability with traces, metrics, and logging\nEnterprise reliability with automatic error recovery\nSecure deployment with proper access controls\nEasy management through AWS console and APIs and support for real-world production workloads.\n\n\n\nAdding comprehensive observability with AgentCore Observability\nAdditionally, AgentCore Runtime integrates seamlessly with AgentCore Observability to provide full visibility into your agent‚Äôs behavior in production. AgentCore Observability automatically captures traces, metrics, and logs from your agent interactions, tool usage, and memory access patterns. In this lab we will see how AgentCore Runtime integrates with CloudWatch GenAI Observability to provide comprehensive monitoring and debugging capabilities.\nFor request tracing, AgentCore Observability captures the complete conversation flow including tool invocations, memory retrievals, and model interactions. For performance monitoring, it tracks response times, success rates, and resource utilization to help optimize your agent‚Äôs performance.\nDuring the observability flow, AgentCore Runtime automatically instruments your agent code and sends telemetry data to CloudWatch. You can then use CloudWatch dashboards and GenAI Observability features to analyze patterns, identify bottlenecks, and troubleshoot issues in real-time.\n\n\nArchitecture for Lab 4\n\n&lt;img src=\"images/architecture_lab4_runtime.png\" width=\"75%\"/&gt; \n\nAgent now runs in AgentCore Runtime with full observability through CloudWatch, serving production traffic with auto-scaling and comprehensive monitoring. Memory and Gateway integrations from previous labs remain fully functional in the production environment.\n\n\nKey Features\n\nServerless Agent Deployment: Transform your local agent into a scalable production service using AgentCore Runtime with minimal code changes\nComprehensive Observability: Full request tracing, performance metrics, and debugging capabilities through CloudWatch GenAI Observability\n\n\n\nPrerequisites\n\nPython 3.12+\nAWS account with appropriate permissions\nDocker, Finch or Podman installed and running\nAmazon Bedrock AgentCore SDK\nStrands Agents framework\n\nNote: You MUST enable CloudWatch Transaction Search to be able to see AgentCore Observability traces in CloudWatch.\n\n\nStep 1: Import Required Libraries\n\n# Import required libraries\nimport os\nimport json\nimport boto3\nfrom strands import Agent\nfrom strands.models import BedrockModel\nfrom lab_helpers.lab2_memory import create_or_get_memory_resource\n\ncreate_or_get_memory_resource()  # Just in case the memory lab wasn't executed\n\n\n\nStep 2: Preparing Your Agent for AgentCore Runtime\n\nCreating the Runtime-Ready Agent\nLet‚Äôs first define the necessary AgentCore Runtime components via Python SDK within our previous local agent implementation.\nObserve the #### AGENTCORE RUNTIME - LINE i #### comments below to see where is the relevant deployment code added. You‚Äôll find 4 such lines that prepare the runtime-ready agent:\n\nImport the Runtime App with from bedrock_agentcore.runtime import BedrockAgentCoreApp\nInitialize the App with app = BedrockAgentCoreApp()\nDecorate our invocation function with @app.entrypoint\nLet AgentCore Runtime control the execution with app.run()\n\n\n%%writefile ./lab_helpers/lab4_runtime.py\nfrom bedrock_agentcore.runtime import (\n    BedrockAgentCoreApp,\n)  #### AGENTCORE RUNTIME - LINE 1 ####\nfrom strands import Agent\nfrom strands.models import BedrockModel\nfrom scripts.utils import get_ssm_parameter\nfrom lab_helpers.lab1_strands_agent import (\n    get_return_policy,\n    get_product_info,\n    get_technical_support,\n    SYSTEM_PROMPT,\n    MODEL_ID,\n)\n\nfrom lab_helpers.lab2_memory import (\n    CustomerSupportMemoryHooks,\n    memory_client,\n    ACTOR_ID,\n    SESSION_ID,\n)\n\n# Lab1 import: Create the Bedrock model\nmodel = BedrockModel(model_id=MODEL_ID)\n\n# Lab2 import : Initialize memory via hooks\nmemory_id = get_ssm_parameter(\"/app/customersupport/agentcore/memory_id\")\nmemory_hooks = CustomerSupportMemoryHooks(\n    memory_id, memory_client, ACTOR_ID, SESSION_ID\n)\n\n# Create the agent with all customer support tools\nagent = Agent(\n    model=model,\n    tools=[get_return_policy, get_product_info, get_technical_support],\n    system_prompt=SYSTEM_PROMPT,\n    hooks=[memory_hooks],\n)\n\n# Initialize the AgentCore Runtime App\napp = BedrockAgentCoreApp()  #### AGENTCORE RUNTIME - LINE 2 ####\n\n\n@app.entrypoint  #### AGENTCORE RUNTIME - LINE 3 ####\ndef invoke(payload):\n    \"\"\"AgentCore Runtime entrypoint function\"\"\"\n    user_input = payload.get(\"prompt\", \"\")\n\n    # Invoke the agent\n    response = agent(user_input)\n    return response.message[\"content\"][0][\"text\"]\n\n\nif __name__ == \"__main__\":\n    app.run()  #### AGENTCORE RUNTIME - LINE 4 ####\n\n\n\nWhat happens behind the scenes?\nWhen you use BedrockAgentCoreApp, it automatically:\n\nCreates an HTTP server that listens on port 8080\nImplements the required /invocations endpoint for processing requests\nImplements the /ping endpoint for health checks\nHandles proper content types and response formats\nManages error handling according to AWS standards\n\n\n\n\nStep 3: Deploying to AgentCore Runtime\nNow let‚Äôs deploy our agent to AgentCore Runtime using the AgentCore Starter Toolkit.\n\nConfigure the Secure Runtime Deployment (AgentCore Runtime + AgentCore Identity)\nFirst we will use our starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we will create and a requirements file. We will also configure the identity authorization using an Amazon Cognito user pool and we will configure the starter kit to auto create the Amazon ECR repository on launch.\nDuring the configure step, your docker file will be generated based on your application code\n\n&lt;img src=\"images/configure.png\" width=\"75%\"/&gt; \n\nNote: The Cognito access_token is valid for 2 hours only. If the access_token expires you can vend another access_token by using the reauthenticate_user method.\n\nfrom lab_helpers.utils import setup_cognito_user_pool, reauthenticate_user\n\nprint(\"Setting up Amazon Cognito user pool...\")\ncognito_config = (\n    setup_cognito_user_pool()\n)  # You'll get your bearer token from this output cell.\nprint(\"Cognito setup completed ‚úì\")\n\n\nfrom bedrock_agentcore_starter_toolkit import Runtime\nfrom lab_helpers.utils import create_agentcore_runtime_execution_role\n\n# Initialize the runtime toolkit\nboto_session = boto3.session.Session()\nregion = boto_session.region_name\n\nexecution_role_arn = create_agentcore_runtime_execution_role()\n\nagentcore_runtime = Runtime()\n\n# Configure the deployment\nresponse = agentcore_runtime.configure(\n    entrypoint=\"lab_helpers/lab4_runtime.py\",\n    execution_role=execution_role_arn,\n    auto_create_ecr=True,\n    requirements_file=\"requirements.txt\",\n    region=region,\n    agent_name=\"customer_support_agent\",\n    authorizer_configuration={\n        \"customJWTAuthorizer\": {\n            \"allowedClients\": [cognito_config.get(\"client_id\")],\n            \"discoveryUrl\": cognito_config.get(\"discovery_url\"),\n        }\n    },\n)\n\nprint(\"Configuration completed:\", response)\n\n\n\nLaunch the Agent\nNow let‚Äôs launch our agent to AgentCore Runtime. This will create an AWS CodeBuild pipeline, the Amazon ECR repository and the AgentCore Runtime components.\n\n&lt;img src=\"images/launch.png\" width=\"100%\"/&gt; \n\n\n# Launch the agent (this will build and deploy the container)\nfrom lab_helpers.utils import put_ssm_parameter\n\nlaunch_result = agentcore_runtime.launch()\nprint(\"Launch completed:\", launch_result.agent_arn)\n\nagent_arn = put_ssm_parameter(\n    \"/app/customersupport/agentcore/runtime_arn\", launch_result.agent_arn\n)\n\n\n\nCheck Deployment Status\nLet‚Äôs wait for the deployment to complete:\n\nimport time\n\n# Wait for the agent to be ready\nstatus_response = agentcore_runtime.status()\nstatus = status_response.endpoint[\"status\"]\n\nend_status = [\"READY\", \"CREATE_FAILED\", \"DELETE_FAILED\", \"UPDATE_FAILED\"]\nwhile status not in end_status:\n    print(f\"Waiting for deployment... Current status: {status}\")\n    time.sleep(10)\n    status_response = agentcore_runtime.status()\n    status = status_response.endpoint[\"status\"]\n\nprint(f\"Final status: {status}\")\n\n\n\n\nStep 4: Invoking Your Deployed Agent\nNow that our agent is deployed and ready, let‚Äôs test it with some queries. We invoke the agent with the right authorization token type. In out case it‚Äôll be Cognito access token. Copy the access token from the cell above\n\n&lt;img src=\"images/invoke.png\" width=\"100%\"/&gt; \n\n\nUsing the AgentCore Starter Toolkit\nWe can validate that the agent works using the AgentCore Starter Toolkit for invocation. The starter toolkit can automatically create a session id for us to query our agent. Alternatively, you can also pass the session id as a parameter during invocation. For demonstration purpose, we will create our own session id.\n\nimport uuid\n\n# Create a session ID for demonstrating session continuity\nsession_id = uuid.uuid4()\n\n# Test different customer support scenarios\nuser_query = \"My Iphone is not connecting with the Bluetooth. What should I do?\"\n\nbearer_token = reauthenticate_user(\n    cognito_config.get(\"client_id\"), \n    cognito_config.get(\"client_secret\")\n)\n\nresponse = agentcore_runtime.invoke(\n    {\"prompt\": user_query}, \n    bearer_token=bearer_token,\n    session_id=str(session_id)\n)\nresponse\n\n\n\nInvoking the agent with session continuity\nSince we are using AgentCore Runtime, we can easily continue our conversation with the same session id.\n\nuser_query = \"I've turned my Bluetooth on and off but it still does not work\"\nresponse = agentcore_runtime.invoke(\n    {\"prompt\": user_query}, \n    bearer_token=bearer_token,\n    session_id=str(session_id)\n)\nresponse\n\n\n\nInvoking the agent with a new user\nIn the example below we have not mentioned the Iphone device in the second query, but our agent still has the context of it. This is due to the AgentCore Runtime session continuity. The agent won‚Äôt know the context for a new user.\n\n# Creating a new session ID for demonstrating new customer\nsession_id2 = uuid.uuid4()\n\nuser_query = \"Still not working. What is going on?\"\nresponse = agentcore_runtime.invoke(\n    {\"prompt\": user_query}, \n    bearer_token=bearer_token,\n    session_id=str(session_id2)\n)\nresponse\n\nIn this case our agent does not have the context anymore and needs more information.\nAnd it is all it takes to have a secure and scalable endpoint for our Agent with no need to manage all the underlying infrastructure!\n\n\n\nStep 5: AgentCore Observability\nAgentCore Observability provides monitoring and tracing capabilities for AI agents using Amazon OpenTelemetry Python Instrumentation and Amazon CloudWatch GenAI Observability.\n\nAgents\nDefault AgentCore Runtime configuration allows for logging our agent‚Äôs traces on CloudWatch by means of AgentCore Observability. These traces can be seen on the AWS CloudWatch GenAI Observability dashboard. Navigate to Cloudwatch ‚Üí GenAI Observability ‚Üí Bedrock AgentCore.\n\n\n\nAgents Overview on CloudWatch\n\n\n\n\nSessions\nThe Sessions view shows the list of all the sessions associated with all agents in your account.\n\n\n\nsessions\n\n\n\n\nTraces\nTrace view lists all traces from your agents in this account. To work with traces:\n\nChoose Filter traces to search for specific traces.\nSort by column name to organize results.\nUnder Actions, select Logs Insights to refine your search by querying across your log and span data or select Export selected traces to export.\n\n\n\n\ntraces\n\n\n\n\n\nCongratulations! üéâ\nYou have successfully completed Lab 4: Deploy to Production - Use AgentCore Runtime with Observability!\nHere is what you accomplished:\n\nProduction-Ready Deployment:\n\nPrepared your agent for production with minimal code changes (only 4 lines added)\nValidated proper session isolation between different customers\nConfirmed session continuity + memory persistence and context awareness per session\n\n\n\nEnterprise-Grade Security & Identity:\n\nImplemented secure authentication using Cognito integration with JWT tokens\nConfigured proper IAM roles and execution permissions for production workloads\nEstablished identity-based access control for secure agent invocation\n\n\n\nComprehensive Observability:\n\nEnabled AgentCore Observability for full request tracing across all customer sessions\nConfigured CloudWatch GenAI Observability dashboard monitoring\n\n\n\nCurrent Limitations (We‚Äôll fix these next!):\n\nDeveloper Focused Interaction - Agent accessible via SDK/API calls but no user-friendly web interface\nManual Session Management - Requires programmatic session creation rather than intuitive user experience\n\n\n\nNext Up Lab 5: Build User Interface ‚Üí\nIn Lab 5, you‚Äôll complete the customer experience by building a user-friendly interface !! Lets go !!"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-01-create-an-agent.html",
    "href": "code_files/aws_agentcore/lab-01-create-an-agent.html",
    "title": "Lab 1: Creating a simple customer support agent prototype",
    "section": "",
    "text": "Amazon Bedrock AgentCore helps you deploying and operating AI agents securely at scale - using any framework and model. It provides you with the capability to move from prototype to production faster.\nIn this 5-labs tutorial, we will demonstrate the end-to-end journey from prototype to production using a Customer Support Agent. For this example we will use Strands Agents, a simple-to-use, code-first framework for building agents and the Anthropic Claude Sonnet 3.7 model from Amazon Bedrock. For your application you can use the framework and model of your choice. It‚Äôs important to note that the concepts covered here can be applied using other frameworks and models as well.\nWorkshop Journey: - Lab 1 (Current): Create Agent Prototype - Build a functional customer support agent - Lab 2: Enhance with Memory - Add conversation context and personalization - Lab 3: Scale with Gateway & Identity - Share tools across agents securely - Lab 4: Deploy to Production - Use AgentCore Runtime with observability - Lab 5: Build User Interface - Create a customer-facing application\nIn this first lab, we‚Äôll build a Customer Support Agent prototype that will evolve throughout the workshop into a production-ready system serving multiple customers with persistent memory, shared tools, and full observability. Our agent will have the following local tools available: - get_return_policy() - Get return policy for specific products - get_product_info() - Get product information - web_search() - Search the web for troubleshooting help - get_technical_support() - Search a Bedrock Knowledge Base"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-01-create-an-agent.html#lab-1-complete",
    "href": "code_files/aws_agentcore/lab-01-create-an-agent.html#lab-1-complete",
    "title": "Lab 1: Creating a simple customer support agent prototype",
    "section": "üéâ Lab 1 Complete!",
    "text": "üéâ Lab 1 Complete!\nYou‚Äôve successfully created a functional Customer Support Agent prototype! Here‚Äôs what you accomplished:\n\nBuilt an agent with 3 custom tools (return policy, product info, web search)\n\nTested multi-tool interactions and web search capabilities\n\nEstablished the foundation for our production journey\n\n\nCurrent Limitations (We‚Äôll fix these!)\n\nSingle user conversation memory - local conversation session, multiple customers need multiple sessions.\nConversation history limited to session - no long term memory or cross session information is available in the conversation.\nTools reusability - tools aren‚Äôt reusable across different agents\n\nRunning locally only - not scalable\nIdentity - No user and/or agent identity or access control\nObservability - Limited observability into agent behavior\nExisting APIs - No access to existing enterprise APIs for customer data\n\n\nNext Up Lab 2: Personalize our agent by adding memory ‚Üí"
  },
  {
    "objectID": "posts/machine_learning_projects/index.html",
    "href": "posts/machine_learning_projects/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/design_portfolio/round_up.html",
    "href": "posts/design_portfolio/round_up.html",
    "title": "RoundUp: Finance Tracking App",
    "section": "",
    "text": "This project was part of my university course ‚ÄúVenturing into Entrepreneurship.‚Äù This was a group project so shout out to my wonderful team members: Prajwal Jagadeesh Kori, Subramania Suresh Sabarish, Phang Jin Jiat Matthias, and Mahir Murtaza, without whom this project wouldn‚Äôt have been such a wonderful success! My main role in the project was UI/UX design and technical feasibility analysis."
  },
  {
    "objectID": "posts/design_portfolio/round_up.html#what-is-it",
    "href": "posts/design_portfolio/round_up.html#what-is-it",
    "title": "RoundUp: Finance Tracking App",
    "section": "What is it?",
    "text": "What is it?\nRoundUp is a mobile app to help users save and invest money without having to reserve large amounts of their salaries."
  },
  {
    "objectID": "posts/design_portfolio/round_up.html#how-does-it-work",
    "href": "posts/design_portfolio/round_up.html#how-does-it-work",
    "title": "RoundUp: Finance Tracking App",
    "section": "How does it work?",
    "text": "How does it work?\nRoundUp operates through two platforms 1) Spend Management Platform (SMP) and 2) Investment Platform (IP). The SMP will round up the user‚Äôs purchases to the next dollar and the rounded up amount will be transferred to their investment wallet to be utilized on the IP. The IP will then allow the users will then allow the users to invest their micro savings into various funds according to their risk appetite. Based on their risk profile, users will be able to invest in funds and gain the corressponding returns."
  },
  {
    "objectID": "posts/design_portfolio/round_up.html#how-does-it-help-users",
    "href": "posts/design_portfolio/round_up.html#how-does-it-help-users",
    "title": "RoundUp: Finance Tracking App",
    "section": "How does it help users?",
    "text": "How does it help users?\nThe combination of the two platforms allows users to save money without feeling the ‚Äúpinch‚Äù of having to set aside a large amount and be able to invest in funds managed by indestry professionals. They will be able to passively invest while gaining actively managed returns."
  },
  {
    "objectID": "posts/design_portfolio/round_up.html#designs",
    "href": "posts/design_portfolio/round_up.html#designs",
    "title": "RoundUp: Finance Tracking App",
    "section": "Designs",
    "text": "Designs"
  },
  {
    "objectID": "posts/machine_learning_projects/Breast Cancer SVM Classifier .html",
    "href": "posts/machine_learning_projects/Breast Cancer SVM Classifier .html",
    "title": "\n\nBreast Cancer Classifier using Support Vector Machine\n\n",
    "section": "",
    "text": "Breast Cancer Classifier using Support Vector Machine"
  },
  {
    "objectID": "posts/machine_learning_projects/Breast Cancer SVM Classifier .html#background",
    "href": "posts/machine_learning_projects/Breast Cancer SVM Classifier .html#background",
    "title": "\n\nBreast Cancer Classifier using Support Vector Machine\n\n",
    "section": "Background:",
    "text": "Background:\nBreast cancer is the most common cancer among women in the world. It accounts for 25% of all cancer cases and affected over 2.1 Million people in 2015 alone. It starts when cells in the breast begin to grow out of control. These cells usually form tumors that can be seen via X-ray or felt as lumps in the breast area.\nEarly diagnosis significantly increases the chances of survival. The key challenge against its detection is how to classify tumors into malignant (cancerous) or benign(non-cancerous). A tumor is considered malignant if the cells can grow into surrounding tissues or spread to distant areas of the body. A benign tumor does not invade nearby tissue nor spread to other parts of the body the way cancerous tumors can. But benign tumors can be serious if they press on vital structures such as blood vessels or nerves.\nMachine Learning techniques can dramatically improve the level of diagnosis of breast cancer. Research shows that experienced physicians can detect cancer with 79% accuracy, while a 91 %( sometimes up to 97%) accuracy can be achieved using Machine Learning techniques."
  },
  {
    "objectID": "posts/machine_learning_projects/Breast Cancer SVM Classifier .html#project-description",
    "href": "posts/machine_learning_projects/Breast Cancer SVM Classifier .html#project-description",
    "title": "\n\nBreast Cancer Classifier using Support Vector Machine\n\n",
    "section": "Project description",
    "text": "Project description\nGithub link\nIn this project, my task is to classify tumors into malignant (cancerous) or benign (non-cancerous) using features obtained from several cell images.\nFeatures are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe the characteristics of the cell nuclei present in the image.\n\n1. Importing necessary libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#Train test split of data\nfrom sklearn.model_selection import train_test_split\n\n#Modelling\nfrom sklearn import svm\n\n#Evaluation\nfrom sklearn.metrics import classification_report\n\n\n\n2. Dataset description\nThere are 700 records and each record has 11 characteristics. The columns/characteristics include 9 predictors, the sample ID, and class of the cell. The fields in each record are:\n\n\n\nField name\nDescription\n\n\n\n\nID\nIdentifier\n\n\nClump\nClumpThickness\n\n\nUnifSize\nUniformity of cell size\n\n\nUnifShape\nUniformity of cell shape\n\n\nMargAdh\nMarginal Adhesion\n\n\nSingEpiSize\nSingle Epithelial Cell Size\n\n\nBareNuc\nBare Nuclei\n\n\nBlandChrom\nBland Chromatin\n\n\nNormNucl\nNormal Nucleoli\n\n\nMit\nMitosis\n\n\nClass\nBenign or malignant\n\n\n\n\n\n3. Importing and analysing dataset\n\ncellDataFrame = pd.read_csv('cell_samples.csv')\ncellDataFrame.head()\n\n\n\n\n\n\n\n\nID\nClump\nUnifSize\nUnifShape\nMargAdh\nSingEpiSize\nBareNuc\nBlandChrom\nNormNucl\nMit\nClass\n\n\n\n\n0\n1000025\n5\n1\n1\n1\n2\n1\n3\n1\n1\n2\n\n\n1\n1002945\n5\n4\n4\n5\n7\n10\n3\n2\n1\n2\n\n\n2\n1015425\n3\n1\n1\n1\n2\n2\n3\n1\n1\n2\n\n\n3\n1016277\n6\n8\n8\n1\n3\n4\n3\n7\n1\n2\n\n\n4\n1017023\n4\n1\n1\n3\n2\n1\n3\n1\n1\n2\n\n\n\n\n\n\n\n\ncellDataFrame.shape\n\n(699, 11)\n\n\n\n#count records under each attribute and check if there are any missing attributes\ncellDataFrame.count()\n\nID             699\nClump          699\nUnifSize       699\nUnifShape      699\nMargAdh        699\nSingEpiSize    699\nBareNuc        699\nBlandChrom     699\nNormNucl       699\nMit            699\nClass          699\ndtype: int64\n\n\n\n#Counting the number of malignant and benign cells in the dataset2\ncellDataFrame['Class'].value_counts()\n\n2    458\n4    241\nName: Class, dtype: int64\n\n\n2 implies Benign and 4 implies Malignant\n\ncellDataFrame.dtypes\n\nID              int64\nClump           int64\nUnifSize        int64\nUnifShape       int64\nMargAdh         int64\nSingEpiSize     int64\nBareNuc        object\nBlandChrom      int64\nNormNucl        int64\nMit             int64\nClass           int64\ndtype: object\n\n\n\n\n4. Split the dataset based on the classes\n\n# combination of over-sampling the minority class and under-sampling the majority class can \n# achieve better classifier performance\n# here the minority class is the malignant cells \nmalignantDataFrame = cellDataFrame[cellDataFrame['Class']==4][0:200]\nmalignantDataFrame.head()\n\n\n\n\n\n\n\n\nID\nClump\nUnifSize\nUnifShape\nMargAdh\nSingEpiSize\nBareNuc\nBlandChrom\nNormNucl\nMit\nClass\n\n\n\n\n5\n1017122\n8\n10\n10\n8\n7\n10\n9\n7\n1\n4\n\n\n12\n1041801\n5\n3\n3\n3\n2\n3\n4\n4\n1\n4\n\n\n14\n1044572\n8\n7\n5\n10\n7\n9\n5\n5\n4\n4\n\n\n15\n1047630\n7\n4\n6\n4\n6\n1\n4\n3\n1\n4\n\n\n18\n1050670\n10\n7\n7\n6\n4\n10\n4\n1\n2\n4\n\n\n\n\n\n\n\n\nbenignDataFrame = cellDataFrame[cellDataFrame['Class']==2][0:200]\nbenignDataFrame.head()\n\n\n\n\n\n\n\n\nID\nClump\nUnifSize\nUnifShape\nMargAdh\nSingEpiSize\nBareNuc\nBlandChrom\nNormNucl\nMit\nClass\n\n\n\n\n0\n1000025\n5\n1\n1\n1\n2\n1\n3\n1\n1\n2\n\n\n1\n1002945\n5\n4\n4\n5\n7\n10\n3\n2\n1\n2\n\n\n2\n1015425\n3\n1\n1\n1\n2\n2\n3\n1\n1\n2\n\n\n3\n1016277\n6\n8\n8\n1\n3\n4\n3\n7\n1\n2\n\n\n4\n1017023\n4\n1\n1\n3\n2\n1\n3\n1\n1\n2\n\n\n\n\n\n\n\n\n\n5. Modify dataset based on requirements\n\n#convert 'BareNuc' from object datatype to int datatype\ncellDataFrame = cellDataFrame[pd.to_numeric(cellDataFrame['BareNuc'], errors='coerce').notnull()]\ncellDataFrame['BareNuc'] = cellDataFrame['BareNuc'].astype('int')\ncellDataFrame.dtypes\n\nID             int64\nClump          int64\nUnifSize       int64\nUnifShape      int64\nMargAdh        int64\nSingEpiSize    int64\nBareNuc        int32\nBlandChrom     int64\nNormNucl       int64\nMit            int64\nClass          int64\ndtype: object\n\n\n\n\n7. Remove unwated columns\nWe will remove columns that won‚Äôt help is in prediction (ID and class)\n\ncellDataFrame.columns\n\nIndex(['ID', 'Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize',\n       'BareNuc', 'BlandChrom', 'NormNucl', 'Mit', 'Class'],\n      dtype='object')\n\n\n\nfeatureDataFrame = cellDataFrame[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize',\n       'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\n\n#convert featureDataFrame into numpy n-dimensional array\n#independent variable\nX=np.asarray(featureDataFrame)\n\n#dependent variable\ny=np.asarray(cellDataFrame['Class'])\n\nX[0:5]\n\narray([[ 5,  1,  1,  1,  2,  1,  3,  1,  1],\n       [ 5,  4,  4,  5,  7, 10,  3,  2,  1],\n       [ 3,  1,  1,  1,  2,  2,  3,  1,  1],\n       [ 6,  8,  8,  1,  3,  4,  3,  7,  1],\n       [ 4,  1,  1,  3,  2,  1,  3,  1,  1]], dtype=int64)\n\n\n\n\n8. Divide the data into train/test set\n\n'''\ncellDataFrame (100) --&gt; Train (80 rows) / Test (20 rows)\n\nTrain(X,y) ## X is a 2D array an y is a 1D array\nTest(X, y)\n'''\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=4) #random state is used to generate a random number \n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\n(546, 9)\n(137, 9)\n(546,)\n(137,)\n\n\n\n\n9. Modelling\nSVC - Support Vector Classifier - those data points near the hyperplane whose perpendicular distance to the hyperplane  If we sum that distance up of all the points near the hyperplane and maximize it such data points would be called SVC  The SVM algorithm offers a choice of kernel functions for performing its processing. Basically, mapping data into a higher dimensional space is called kerneling.  The mathematical function used for the trandformation is known as kernel function, and can be of different types, such as,\n\nLinear\nPolynomial\nRadial Basis Function (RBF)\nSigmoid\n\nEach of these functions has its characteristics, its pros and cons, and its equations, but as there‚Äôs no easy way of knowing which function performs best with any given dataset, we usually choose different functions and compare the results.\nC- The Regularization parameter - tells the SVM optimization how much you want to avoid misclassifying each training example. Here C is the penalty parameter, which represents misclassification or error term. The misclassification or error term tells the SVM optimization how much error is bearable. This is how you can control the trade-off between decision boundary and misclassification term. A smaller value of C creates a small-margin hyperplane and a larger value of C creates a larger-margin hyperplane.\n\nclassifier = svm.SVC(kernel='linear', gamma='auto', C=2)\nclassifier.fit(X_train, y_train)\n\ny_predict = classifier.predict(X_test)\n\n\n\n10. Evaluation\n\nprint(classification_report(y_test, y_predict))\n\n              precision    recall  f1-score   support\n\n           2       1.00      0.94      0.97        90\n           4       0.90      1.00      0.95        47\n\n    accuracy                           0.96       137\n   macro avg       0.95      0.97      0.96       137\nweighted avg       0.97      0.96      0.96       137\n\n\n\nprecision = true_positive/(true_positive + false_positive)\nrecall = true_positive/(true_positive + false_negative) = true_positive/total_actual_positive\nF1: harmonical mean of precision = 2((precision  recall)/(precision + recall))\nsupport: how many instances of the class were there\n\n\nHyperparameter tuning for SVM model - C, gamma, epsilon, kernel\n\n1. GridSearchCV\n\n\n2. RandomizedSearchCV"
  },
  {
    "objectID": "posts/machine_learning_projects/AgentCore.html#project-goal",
    "href": "posts/machine_learning_projects/AgentCore.html#project-goal",
    "title": "Building a Customer Support Agent Using Amazon BedRock AgentCore",
    "section": "Project Goal",
    "text": "Project Goal\nThis project is part of the AWS Users Group Workshop on 17th September, 2025. The goal of the project is to build a comprehensive, production ready Customer Support Agent using Amazon BedRock AgentCore.\n\nBusiness Scenario\nYou work for TechCorp, an e-commerce company that receives hundreds of customer support requests daily.\nCustomers contact support for various reasons:\n\n\nProduct Information: Getting specifications, pricing, and availability details\n\n\nPolicy Questions: Understanding return policies, shipping costs, and business hours\n\n\nCurrently, your support team spends significant time on repetitive tasks, leading to longer wait times and higher operational costs. You need an AI solution that can handle routine inquiries while escalating complex cases to human agents."
  },
  {
    "objectID": "posts/machine_learning_projects/AgentCore.html#concepts-to-know",
    "href": "posts/machine_learning_projects/AgentCore.html#concepts-to-know",
    "title": "Building a Customer Support Agent Using Amazon BedRock AgentCore",
    "section": "Concepts to know",
    "text": "Concepts to know\n\nAmazon Bedrock AgentCore\nA fully managed service that enables you to deploy and operate highly capable AI agents securely at scale. AgentCore services can be used together or independently and work with any framework including Strands Agents, LangGraph, CrewAI, and LlamaIndex, as well as any foundation model in or outside of Amazon Bedrock, giving you the ultimate flexibility. It serves developers and enterprises who need 1) robust, secure, and scalable infrastructure to support dynamic execution paths at runtime, 2) controls to monitor behavior, 3) powerful tools to enhance agents, and 4) the flexibility to adapt as the landscape evolves.\n\n\nModel Context Protocol (MCP)\nAn open-spourced standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g.¬†local files, databases), tools (e.g.¬†search engines, calculators) and workflows (e.g.¬†specialized prompts)‚Äîenabling them to access key information and perform tasks. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems. Another standardized protocol is called Agent2Agent (A2A).\n\n\nStrands Agent\nStrands Agents is a simple-to-use, code-first framework for building agents. With Strands, developers can simply define a prompt and a list of tools in code to build an agent, then test it locally and deploy it to the cloud. Like the two strands of DNA, Strands connects two core pieces of the agent together: the model and the tools. Strands plans the agent‚Äôs next steps and executes tools using the advanced reasoning capabilities of models. For more complex agent use cases, developers can customize their agent‚Äôs behavior in Strands. For example, you can specify how tools are selected, customize how context is managed, choose where session state and memory are stored, and build multi-agent applications. Strands can run anywhere and can support any model with reasoning and tool use capabilities, including models in Amazon Bedrock, Anthropic, Ollama, Meta, and other providers through LiteLLM."
  },
  {
    "objectID": "posts/machine_learning_projects/AgentCore.html#architecture-overview",
    "href": "posts/machine_learning_projects/AgentCore.html#architecture-overview",
    "title": "Building a Customer Support Agent Using Amazon BedRock AgentCore",
    "section": "Architecture Overview",
    "text": "Architecture Overview\n\n\n\nArchitecture Diagram"
  },
  {
    "objectID": "posts/machine_learning_projects/AgentCore.html#lab-1",
    "href": "posts/machine_learning_projects/AgentCore.html#lab-1",
    "title": "Building a Customer Support Agent Using Amazon BedRock AgentCore",
    "section": "Lab 1",
    "text": "Lab 1\nIn this lab, we will build a basic Customer Support Agent prototype using Strands Agents. This agent will have the following local tools available: Jupyter Notebook\n\n\n\n\n\nTool Function\n\n\nDescription\n\n\n\n\n\n\nget_return_policy()\n\n\nGet return policy for specific products\n\n\n\n\nget_product_info()\n\n\nGet product information\n\n\n\n\nweb_search()\n\n\nSearch web for updated product information\n\n\n\n\n\nThe main goal of this lab is to:\n\n\nCreate tools using the @tool decorator\n\n\nInitialize a Strands Agent with model and tools\n\n\nTest Agent locally in a Jupyter Notebook\n\n\n\nArchitecture for Lab 1\n\n\n\nLab 1 Architecture Diagram\n\n\n\n\nStep 1: Create Customer Support Tools\nTo provide more capabilities to the Agent, we can build specialized functions that can interact with external systems and data sources. Each tool represents a specific capability that allows the agent to take actions in the real world, from looking up orders to checking policies."
  },
  {
    "objectID": "posts/machine_learning_projects/AgentCore.html#lab-2",
    "href": "posts/machine_learning_projects/AgentCore.html#lab-2",
    "title": "Building a Customer Support Agent Using Amazon BedRock AgentCore",
    "section": "Lab 2",
    "text": "Lab 2\nThis lab focuses on enhancing an agent with memory. The reality for most AI agents today: Every conversation starts from zero, creating:\n\n\nFrustrated customers who must repeat their information repeatedly\n\n\nInefficient support that cannot build on previous interactions\n\n\nLost opportunities to provide personalized, proactive service\n\n\nPoor customer satisfaction due to impersonal, generic responses\n\n\nAmazon BedRock AgentCore Memory addresses this limitation by providing a managed service that enables AI agents to maintain context over time, remember important facts, and deliver consistent, personalized experiences. AgentCore Memory operates on two levels:\n\n\nShort-Term Memory: Immediate conversation context and session-based information that provides continuity within a single interaction or closely related sessions.\n\n\nLong-Term Memory: Persistent information extracted and stored across multiple conversations, including facts, preferences, and summaries that enable personalized experiences over time.\n\n\nIn this lab, you‚Äôll upgrade your Lab 1 prototype to deliver exceptional customer experiences through intelligent memory. Our agent will evolve from a forgetful prototype to a customer-aware assistant that:\n\n\n‚ÄúWelcome back, Sarah!‚Äù - Instantly recognizes returning customers\n\n\n‚ÄúI remember you prefer email updates‚Äù - Recalls individual preferences automatically\n\n\n‚ÄúFollowing up on your laptop issue from last month‚Äù - Connects related conversations seamlessly\n\n\n‚ÄúBased on your purchase history, here‚Äôs what I recommend‚Äù - Provides personalized suggestions\n\n\n\nArchitecture for Lab 2\n\n\n\nLab 2 Architecture Diagram\n\n\n\n\nStep 1: Create AgentCore Memory Resources\nOur first step (This is a one-time setup) is to create a managed agentcore memory resource with multiple strategies (USER_PREFERENCE and SEMANTIC) to store comprehensive customer context, enabling persistent recall across conversations and balanced behavioral/factual insights."
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "",
    "text": "In this Lab, you will learn how to integrate tools available in your organization with the Customer Support Agent using the Amazon Bedrock Gateway.\nThe Model Context Protocol (MCP) is an open protocol that standardizes how applications provide tools and context to Large Language Models (LLMs).\nWith Amazon Bedrock Agent Core Gateway, developers can convert APIs, Lambda functions, and existing services into MCP-compatible tools and make them available to agents through Gateway endpoints with just a few lines of code.\nWorkshop Journey:\n\nLab 1 (Done): Create Agent Prototype - Built a functional customer support agent\nLab 2 (Done): Enhance with Memory - Added conversation context and personalization\nLab 3 (Current): Scale with Gateway & Identity - Shared tools across agents securely\nLab 4: Deploy to Production - Used AgentCore Runtime with observability\nLab 5: Build User Interface - Create a customer-facing application\n\n\n\nCurrent State (Lab 1-2): Each agent has its own copy of tools. I practice that is not scalable and leads to:\n\nCode duplication across different agents\nInconsistent tool behavior and maintenance overhead\nNo centralized security or access control\nDifficulty scaling to multiple use cases\n\nAfter this lab, we will have centralized, reusable tools that can serve:\n\nCustomer Support Agent (our current use case)\nSales Agent (needs same product info and customer data)\nInventory Agent (needs same product info and warranty checking)\nReturns Processing Agent (needs return policies and customer profiles)\n\nand other use cases.\n\n\n\nAdditionally, AgentCore Gateway requires you to securely authenticate both inbound and outbound connections. AgentCore Identity provides seamless agent identity and access management across AWS services and third-party applications such as Slack and Zoom while supporting any standard identity providers such as Okta, Entra, and Amazon Cognito. In this lab we will see how AgentCore Gateway integrates with AgentCore Identity to provide secure connections via inbound and outbound authentication.\nFor the inbound authentication, the AgentCore Gateway analyzes the OAuth token passed during invocation to decide allow or deny the access to a tool in the gateway. If a tool needs access to external resources, the AgentCore Gateway can use outbound authentication via API Key, IAM or OAuth Token to allow or deny the access to the external resource.\nDuring the inbound authorization flow, an agent or the MCP client calls an MCP tool in the AgentCore Gateway adding an OAuth access token (generated from the user‚Äôs IdP). AgentCore Gateway then validates the OAuth access token and performs inbound authorization.\nIf the tool running in AgentCore Gateway needs to access external resources, OAuth will retrieve credentials of downstream resources using the resource credential provider for the Gateway target. AgentCore Gateway pass the authorization credentials to the caller to get access to the downstream API."
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#overview",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#overview",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "",
    "text": "In this Lab, you will learn how to integrate tools available in your organization with the Customer Support Agent using the Amazon Bedrock Gateway.\nThe Model Context Protocol (MCP) is an open protocol that standardizes how applications provide tools and context to Large Language Models (LLMs).\nWith Amazon Bedrock Agent Core Gateway, developers can convert APIs, Lambda functions, and existing services into MCP-compatible tools and make them available to agents through Gateway endpoints with just a few lines of code.\nWorkshop Journey:\n\nLab 1 (Done): Create Agent Prototype - Built a functional customer support agent\nLab 2 (Done): Enhance with Memory - Added conversation context and personalization\nLab 3 (Current): Scale with Gateway & Identity - Shared tools across agents securely\nLab 4: Deploy to Production - Used AgentCore Runtime with observability\nLab 5: Build User Interface - Create a customer-facing application\n\n\n\nCurrent State (Lab 1-2): Each agent has its own copy of tools. I practice that is not scalable and leads to:\n\nCode duplication across different agents\nInconsistent tool behavior and maintenance overhead\nNo centralized security or access control\nDifficulty scaling to multiple use cases\n\nAfter this lab, we will have centralized, reusable tools that can serve:\n\nCustomer Support Agent (our current use case)\nSales Agent (needs same product info and customer data)\nInventory Agent (needs same product info and warranty checking)\nReturns Processing Agent (needs return policies and customer profiles)\n\nand other use cases.\n\n\n\nAdditionally, AgentCore Gateway requires you to securely authenticate both inbound and outbound connections. AgentCore Identity provides seamless agent identity and access management across AWS services and third-party applications such as Slack and Zoom while supporting any standard identity providers such as Okta, Entra, and Amazon Cognito. In this lab we will see how AgentCore Gateway integrates with AgentCore Identity to provide secure connections via inbound and outbound authentication.\nFor the inbound authentication, the AgentCore Gateway analyzes the OAuth token passed during invocation to decide allow or deny the access to a tool in the gateway. If a tool needs access to external resources, the AgentCore Gateway can use outbound authentication via API Key, IAM or OAuth Token to allow or deny the access to the external resource.\nDuring the inbound authorization flow, an agent or the MCP client calls an MCP tool in the AgentCore Gateway adding an OAuth access token (generated from the user‚Äôs IdP). AgentCore Gateway then validates the OAuth access token and performs inbound authorization.\nIf the tool running in AgentCore Gateway needs to access external resources, OAuth will retrieve credentials of downstream resources using the resource credential provider for the Gateway target. AgentCore Gateway pass the authorization credentials to the caller to get access to the downstream API."
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#architecture-for-lab-3",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#architecture-for-lab-3",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Architecture for Lab 3",
    "text": "Architecture for Lab 3\n\n&lt;img src=\"images/architecture_lab3_gateway.png\" width=\"75%\"/&gt;\n\nWeb search tool is now centralized in AgentCore Gateway with secure identity-based access control. Multiple agents and use cases can share the same tool securely. We will also reuse the check_warranty() tool built for other applications and add the web_search() tool for use within other applications. get_product_info(), get_return_policy(), and get_technical_support remain as local tools as they are specific to the customer support use case\n\nKey Features\n\nSeamlessly integrate AWS Lambda functions: This example shows how to integrate your Agent with existing AWS Lambda functions to check the warranty of an item and to get the customer profile using Amazon Bedrock AgentCore Gateway.\nSecure your Gateway endpoint with Inbound Auth: Only an Agent providing a valid JWT token can connect to the endpoint to use the tools\nConfigure the Agent to use the MCP endpoint: The Agent gets a valid JWT token and uses it to connect to the MCP endpoint provided by AgentCore Gateway"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#prerequisites",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#prerequisites",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nPython 3.12+\nAWS credentials configured\nAnthropic Claude 3.7 enabled on Amazon Bedrock\nComplete Lab 2 Add memory to the Customer Support Agent\nThese resources are created for you within an AWS workshop account\n\nAWS Lambda function\nAWS Lambda Execution IAM Role\nAgentCore Gateway IAM Role\nDynamoDB tables used by the AWS Lambda function.\nCognito User Pool and User Pool Client"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-1-install-and-import-required-libraries",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-1-install-and-import-required-libraries",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 1: Install and import required libraries",
    "text": "Step 1: Install and import required libraries\n\n# Install required packages\n%pip install strands-agents \"boto3&gt;=1.39.15\" strands-agents-tools bedrock_agentcore ddgs -q\n\n\n# Import libraries\nfrom strands import Agent\nfrom strands.models import BedrockModel\nfrom strands.tools.mcp import MCPClient\nimport os\nimport sys\nimport boto3\nimport json\nfrom bedrock_agentcore.identity.auth import requires_access_token\nfrom mcp.client.streamable_http import streamablehttp_client\nimport requests\n\nfrom scripts.utils import get_ssm_parameter, put_ssm_parameter, load_api_spec, get_cognito_client_secret\n\nsts_client = boto3.client('sts')\n\n# Get AWS account details\nREGION = boto3.session.Session().region_name\n\ngateway_client = boto3.client(\n    \"bedrock-agentcore-control\",\n    region_name=REGION,\n)\n\nprint(\"‚úÖ Libraries imported successfully!\")"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-2-give-our-agent-a-tool-to-access-existing-customer-data",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-2-give-our-agent-a-tool-to-access-existing-customer-data",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 2: Give our agent a tool to access existing customer data",
    "text": "Step 2: Give our agent a tool to access existing customer data\nAgentCore Gateway simplifies agent tool integration in three key ways:\nUniversal MCP Support: Instantly make your tools compatible with any agent framework by exposing them through AgentCore Gateway‚Äôs MCP standard\nSimple REST Integration: Transform existing REST services into agent tools by just adding them as AgentCore Gateway targets\nLambda Flexibility: Expose Lambda functions as MCP endpoints that can call any API - demonstrated here with a function that checks warranty status\nAgentCore Gateway populates the Lambda context with the name of the tool to invoke, while the parameters passed to the tool are provided in the Lambda event:\nextended_tool_name = context.client_context.custom[\"bedrockAgentCoreToolName\"]\nresource = extended_tool_name.split(\"___\")[1]\nLambda function\ndef lambda_handler(event, context):\n    if get_tool_name(event) == \"check_warranty_status\":\n        serial_number = get_named_parameter(event=event, name=\"serial_number\")\n        customer_email = get_named_parameter(event=event, name=\"customer_email\")\n\n        warranty_status = check_warranty_status(serial_number, customer_email)\n        return {\"statusCode\": 200, \"body\": warranty_status}"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-3-convert-your-web-search-tool-to-mcp",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-3-convert-your-web-search-tool-to-mcp",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 3 Convert your web search tool to MCP",
    "text": "Step 3 Convert your web search tool to MCP\nNow that we are developing an MCP server using AgentCore Gateway, we can MCP-ify any tools which we think we‚Äôll use for multiple Agents. One of these tools might be a web search tool like we built in Lab1. As a result, we also converted the web search tool from Lab 1 into a Lambda tool within our AgentCore Gateway:\nWeb search Lambda\nfrom ddgs import DDGS\n\n\ndef web_search(keywords: str, region: str = \"us-en\", max_results: int = 5) -&gt; str:\n    \"\"\"Search the web for updated information.\n    \n    Args:\n        keywords (str): The search query keywords.\n        region (str): The search region: wt-wt, us-en, uk-en, ru-ru, etc.\n        max_results (int): The maximum number of results to return.\n        \n    Returns:\n        List of dictionaries with search results.\n    \"\"\"\n    try:\n        results = DDGS().text(keywords, region=region, max_results=max_results)\n        return results if results else \"No results found.\"\n    except Exception as e:\n        return f\"Search error: {str(e)}\"\n\n\nprint(\"‚úÖ Web search tool ready\")"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-4-create-your-function-definition-metadata",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-4-create-your-function-definition-metadata",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 4 Create your function definition metadata",
    "text": "Step 4 Create your function definition metadata\nLastly, we need to write tool schema which describes the tools implemented by your Lambda function.\nThis file has been already defined in prerequisite/lambda/api_spec.json\n[\n    {\n        \"name\": \"check_warranty_status\",\n        \"description\": \"Check the warranty status of a product using its serial number and optionally verify via email\",\n        \"inputSchema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"serial_number\": {\n                    \"type\": \"string\"\n                },\n                \"customer_email\": {\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"serial_number\"\n            ]\n        }\n    },\n    {\n        \"name\": \"web_search\",\n        \"description\": \"Search the web for updated information using DuckDuckGo\",\n        \"inputSchema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"keywords\": {\n                    \"type\": \"string\",\n                    \"description\": \"The search query keywords\"\n                },\n                \"region\": {\n                    \"type\": \"string\",\n                    \"description\": \"The search region (e.g., us-en, uk-en, ru-ru)\"\n                },\n                \"max_results\": {\n                    \"type\": \"integer\",\n                    \"description\": \"The maximum number of results to return\"\n                }\n            },\n            \"required\": [\n                \"keywords\"\n            ]\n        }\n    }\n]"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-5.-create-your-agentcore-gateway",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-5.-create-your-agentcore-gateway",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 5. Create your AgentCore Gateway",
    "text": "Step 5. Create your AgentCore Gateway\nNow let‚Äôs create the AgentCore Gateway to expose the Lambda function as MCP-compatible endpoint.\nTo validate the callers authorized to invoke our tools we need to configure the Inbound Auth.\nInbound Auth works using OAuth authorization, the standard for MCP servers. With OAuth the client application must authenticate with the OAuth authorizer before using the Gateway. Your client would receive an access token which is used at runtime.\nYou need to specify an OAuth discovery server and client IDs. The Cloudformation provided with the workshop already provisioned the Cognito UserPool and UserPoolClient and it stored the discovery URL and the Client ID in dedicated SSM parameters.\n\ngateway_name = \"customersupport-gw\"\n\nauth_config = {\n    \"customJWTAuthorizer\": {\n        \"allowedClients\": [\n            get_ssm_parameter(\"/app/customersupport/agentcore/machine_client_id\")\n        ],\n        \"discoveryUrl\": get_ssm_parameter(\"/app/customersupport/agentcore/cognito_discovery_url\")\n    }\n}\n\ntry:\n    # create new gateway\n    print(f\"Creating gateway in region {REGION} with name: {gateway_name}\")\n\n    create_response = gateway_client.create_gateway(\n        name=gateway_name,\n        roleArn= get_ssm_parameter(\"/app/customersupport/agentcore/gateway_iam_role\"),\n        protocolType=\"MCP\",\n        authorizerType=\"CUSTOM_JWT\",\n        authorizerConfiguration=auth_config,\n        description=\"Customer Support AgentCore Gateway\",\n    )\n\n    gateway_id = create_response[\"gatewayId\"]\n\n    gateway = {\n        \"id\": gateway_id,\n        \"name\": gateway_name,\n        \"gateway_url\": create_response[\"gatewayUrl\"],\n        \"gateway_arn\": create_response[\"gatewayArn\"],\n    }\n    put_ssm_parameter(\"/app/customersupport/agentcore/gateway_id\", gateway_id)\n\n    print(f\"‚úÖ Gateway created successfully with ID: {gateway_id}\")\n\nexcept Exception as e:\n    # If gateway exists, collect existing gateway ID from SSM\n    existing_gateway_id = get_ssm_parameter(\"/app/customersupport/agentcore/gateway_id\")\n    print(f\"Found existing gateway with ID: {existing_gateway_id}\")\n    \n    # Get existing gateway details\n    gateway_response = gateway_client.get_gateway(gatewayIdentifier=existing_gateway_id)\n    gateway = {\n        \"id\": existing_gateway_id,\n        \"name\": gateway_response[\"name\"],\n        \"gateway_url\": gateway_response[\"gatewayUrl\"],\n        \"gateway_arn\": gateway_response[\"gatewayArn\"],\n    }\n    gateway_id = gateway['id']"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-6.-add-the-lambda-function-target",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-6.-add-the-lambda-function-target",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 6. Add the Lambda function Target",
    "text": "Step 6. Add the Lambda function Target\nNow we will use the previously defined function definitions from prerequisite/lambda/api_spec.json to create a Lambda target within our Agent Gateway. This will define the tools that your gateway will host.\nGateway allows you to attach multiple targets to a Gateway and you can change the targets / tools attached to a gateway at any point. Each target can have its own credential provider, but Gateway becomes a single MCP URL enabling access to all of the relevant tools for an agent across myriad APIs.\n\ndef load_api_spec(file_path: str) -&gt; list:\n    with open(file_path, \"r\") as f:\n        data = json.load(f)\n        \n    if not isinstance(data, list):\n        raise ValueError(\"Expected a list in the JSON file\")\n    return data\n\ntry:\n    api_spec_file = \"./prerequisite/lambda/api_spec.json\"\n\n    # Validate API spec file exists\n    if not os.path.exists(api_spec_file):\n        print(f\"‚ùå API specification file not found: {api_spec_file}\")\n        sys.exit(1)\n\n    api_spec = load_api_spec(api_spec_file)\n \n    # Use Cognito for Inbound OAuth to our Gateway\n    lambda_target_config = {\n        \"mcp\": {\n            \"lambda\": {\n                \"lambdaArn\": get_ssm_parameter(\"/app/customersupport/agentcore/lambda_arn\"),\n                \"toolSchema\": {\"inlinePayload\": api_spec},\n            }\n        }\n    }\n\n\n    # Create gateway target\n    credential_config = [{\"credentialProviderType\": \"GATEWAY_IAM_ROLE\"}]\n\n    create_target_response = gateway_client.create_gateway_target(\n        gatewayIdentifier=gateway_id,\n        name=\"LambdaUsingSDK\",\n        description=\"Lambda Target using SDK\",\n        targetConfiguration=lambda_target_config,\n        credentialProviderConfigurations=credential_config,\n    )\n\n    print(f\"‚úÖ Gateway target created: {create_target_response['targetId']}\")\n\nexcept Exception as e:\n    print(f\"‚ùå Error creating gateway target: {str(e)}\")"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-7-add-our-new-mcp-based-tools-to-our-support-agent",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-7-add-our-new-mcp-based-tools-to-our-support-agent",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 7: Add our new MCP-based tools to our support agent",
    "text": "Step 7: Add our new MCP-based tools to our support agent\nHere we integrate our authentication token from Cognito into an MCPClient from Strands SDK to create an MCP Server object to integrate with our Strands Agent\n\ndef get_token(client_id: str, client_secret: str, scope_string: str, url: str) -&gt; dict:\n    try:\n        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n        data = {\n            \"grant_type\": \"client_credentials\",\n            \"client_id\": client_id,\n            \"client_secret\": client_secret,\n            \"scope\": scope_string,\n\n        }\n        response = requests.post(url, headers=headers, data=data)\n        response.raise_for_status()\n        return response.json()\n\n    except requests.exceptions.RequestException as err:\n        return {\"error\": str(err)}"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-7.1.-set-up-a-secure-mcp-client-object",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-7.1.-set-up-a-secure-mcp-client-object",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 7.1. Set up a secure MCP client object",
    "text": "Step 7.1. Set up a secure MCP client object\n\ngateway_access_token = get_token(\n    get_ssm_parameter(\"/app/customersupport/agentcore/machine_client_id\"),\n    get_cognito_client_secret(),\n    get_ssm_parameter(\"/app/customersupport/agentcore/cognito_auth_scope\"),\n    get_ssm_parameter(\"/app/customersupport/agentcore/cognito_token_url\"))\n\nprint(f\"Gateway Endpoint - MCP URL: {gateway['gateway_url']}\")\n\n# Set up MCP client\nmcp_client = MCPClient(\n    lambda: streamablehttp_client(\n        gateway['gateway_url'],\n        headers={\"Authorization\": f\"Bearer {gateway_access_token['access_token']}\"},\n    )\n)"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-7.2.-access-tools-in-our-agent-using-our-mcp-client",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-7.2.-access-tools-in-our-agent-using-our-mcp-client",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 7.2. Access tools in our agent using our MCP client",
    "text": "Step 7.2. Access tools in our agent using our MCP client\nNow we will create our Strands Agent using the AgentCore Gateway we built along with the resources from previous labs. Our agent now uses a mix of local tools via our Strands Agent and MCP tools via AgentCore Gateway\n\nfrom lab_helpers.lab1_strands_agent import get_product_info, get_return_policy, get_technical_support, SYSTEM_PROMPT\nfrom lab_helpers.lab2_memory import CustomerSupportMemoryHooks,create_or_get_memory_resource \nimport uuid\nfrom bedrock_agentcore.memory import MemoryClient\n\nmemory_client = MemoryClient(region_name=REGION)\n\nmemory_id = create_or_get_memory_resource()\nSESSION_ID = str(uuid.uuid4())\nCUSTOMER_ID = \"customer_001\"\nmemory_hooks = CustomerSupportMemoryHooks(memory_id, memory_client, CUSTOMER_ID, SESSION_ID)\n\n# Initialize the Bedrock model\nmodel_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\nmodel = BedrockModel(\n    model_id=model_id,\n    temperature=0.3,  # Balanced between creativity and consistency\n    region_name=REGION\n)\n\ntry:\n    mcp_client.start()\nexcept Exception as e:\n    print(f\"Error initializing agent: {str(e)}\")\n\ntools = (\n            [\n                get_product_info,\n                get_return_policy,\n                get_technical_support\n            ]\n            + mcp_client.list_tools_sync()\n        )\n\n# Create the customer support agent\nagent = Agent(\n    model=model,\n    tools=tools,\n    hooks=[memory_hooks],\n    system_prompt=SYSTEM_PROMPT\n)\n\nprint(\"‚úÖ Customer support agent created successfully!\")"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-8-test-the-agent-with-mcp-tool-access-to-existing-apis",
    "href": "code_files/aws_agentcore/lab-03-agentcore-gateway.html#step-8-test-the-agent-with-mcp-tool-access-to-existing-apis",
    "title": "Lab 3: Securely connect tools to your Agent with AgentCore Gateway",
    "section": "Step 8: Test the agent with MCP tool access to existing APIs‚Äù",
    "text": "Step 8: Test the agent with MCP tool access to existing APIs‚Äù\nLet‚Äôs test our agent with sample queries to ensure all features work correctly.\n\ntest_prompts = [\n    # Warranty Checks\n    \"List all of your tools\",\n    \"I bought an iphone 14 last month. I don't like it because it heats up. How do I solve it?\",\n    \"I have a Gaming Console Pro device , I want to check my warranty status, warranty serial number is MNO33333333.\",\n    \"What are the warranty support guidelines?\",\n    \"How can I fix Lenovo Thinkpad with a blue screen\",\n    \"Tell me detailed information about the technical documentation on installing a new CPU\"\n]\n\n# Function to test the agent\ndef test_agent_responses(agent, prompts):\n    for i, prompt in enumerate(prompts, 1):\n        print(f\"\\nTest Case {i}: {prompt}\")\n        print(\"-\" * 50)\n        try:\n            response = agent(prompt)\n        except Exception as e:\n            print(f\"Error: {str(e)}\")\n        print(\"-\" * 50)\n\n# Run the tests\ntest_agent_responses(agent, test_prompts)\n\nprint(\"\\\\n‚úÖ Basic testing completed!\")\n\n\nCongratulations! üéâ\nYou have successfully completed Lab 3: Securely connect tools to your Agent with AgentCore Gateway\nWhat You Accomplished:\n\nTool Centralization & Reusability:\n\nMigrated web search from local tool to centralized AgentCore Gateway\nIntegrated existing enterprise Lambda functions (warranty check, customer profile)\nCreated a shared tool infrastructure that multiple agent types can access\n\n\n\nEnterprise-Grade Security:\n\nImplemented JWT-based authentication with Cognito integration\nConfigured secure inbound authorization for gateway access\nEstablished identity-based access control for tool usage\n\n\n\nScalable Architecture Foundation:\n\nBuilt reusable tools that serve multiple use cases (customer support, sales, returns processing)\nEliminated code duplication across different agents\nCreated centralized management for tool updates and maintenance\n\n\n\nCurrent Limitations (We‚Äôll fix these next!):\n\nLocal Development Environment - Still running on your laptop, not production-ready\nLimited Observability - No comprehensive monitoring of agent behavior and performance\nManual Scaling - Cannot automatically handle increased load or multiple concurrent users\n\n\n\nNext Up: Lab 4 - Deploying to Production with AgentCore Runtime\nIn Lab 4, you‚Äôll transform your prototype into a production-ready system with:\n\nAgentCore Runtime for scalable agent deployment\nComprehensive observability with metrics, logging, and tracing\nAuto-scaling capabilities to handle real-world traffic\n\n\n\n\nResources\n\nAmazon Bedrock Agent Core Gateway\nStrands Agents Documentation\nOfficial Customer Support Sample"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "",
    "text": "This notebook provides a comprehensive cleanup process for all resources created during the AgentCore End-to-End tutorial."
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html#overview",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html#overview",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "Overview",
    "text": "Overview\nThis cleanup process will remove: - Memory: AgentCore Memory resources and stored data - Runtime: Agent runtime instances and ECR repositories - Security: Execution roles, and Authorization Provider resources - Observability: CloudWatch log groups and streams - Local Files: Generated configuration and code files\n‚ö†Ô∏è Important: This cleanup is irreversible. Make sure you have saved any important data (if needed) before proceeding."
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html#step-1-import-required-dependencies",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html#step-1-import-required-dependencies",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "Step 1: Import Required Dependencies",
    "text": "Step 1: Import Required Dependencies\nLoad all necessary modules and helper functions for the cleanup process.\n\nimport boto3\nimport os\nfrom botocore.exceptions import ClientError\n\nfrom bedrock_agentcore_starter_toolkit import Runtime\nfrom lab_helpers.lab2_memory import delete_memory, REGION\nfrom lab_helpers.utils import (\n    delete_agentcore_runtime_execution_role,\n    delete_ssm_parameter,\n    cleanup_cognito_resources,\n    get_customer_support_secret,\n    delete_customer_support_secret,\n    agentcore_memory_cleanup,\n    gateway_target_cleanup,\n    runtime_resource_cleanup,\n    delete_observability_resources,\n    local_file_cleanup\n)\n\nprint(\"‚úÖ Dependencies imported successfully\")\nprint(f\"üåç Working in region: {REGION}\")"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html#step-2-clean-up-memory-resources",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html#step-2-clean-up-memory-resources",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "Step 2: Clean Up Memory Resources",
    "text": "Step 2: Clean Up Memory Resources\nRemove AgentCore Memory resources and associated data.\n\nprint(\"üß† Starting Memory cleanup...\")\nagentcore_memory_cleanup()"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html#step-3-clean-up-runtime-resources",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html#step-3-clean-up-runtime-resources",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "Step 3: Clean Up Runtime Resources",
    "text": "Step 3: Clean Up Runtime Resources\nRemove the AgentCore Runtime, ECR repository, and associated AWS resources.\n\nprint(\"üöÄ Starting Runtime cleanup...\")\nruntime_resource_cleanup()"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html#step-4-clean-up-gateway-resources",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html#step-4-clean-up-gateway-resources",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "Step 4: Clean Up Gateway Resources",
    "text": "Step 4: Clean Up Gateway Resources\nRemove targets, Gateway\n\nprint(\"‚öôÔ∏è Starting Gateway Cleanup...\")\ngateway_target_cleanup()"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html#step-5-clean-up-security-resources",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html#step-5-clean-up-security-resources",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "Step 5: Clean Up Security Resources",
    "text": "Step 5: Clean Up Security Resources\nRemove execution roles, and authentication resources.\n\nprint(\"üõ°Ô∏è  Starting Security cleanup...\")\nimport json\ntry:\n    # bedrock_client = boto3.client(\"bedrock\", region_name=REGION)\n    \n    # Delete execution role\n    print(\"  üóëÔ∏è  Deleting AgentCore Runtime execution role...\")\n    delete_agentcore_runtime_execution_role()\n    print(\"  ‚úÖ Execution role deleted\")\n    \n    # Delete SSM parameter\n    print(\"  üóëÔ∏è  Deleting SSM parameter...\")\n    delete_ssm_parameter(\"/app/customersupport/agentcore/runtime_arn\")\n    print(\"  ‚úÖ SSM parameter deleted\")\n    \n    # Clean up Cognito and secrets\n    print(\"  üóëÔ∏è  Cleaning up Cognito resources...\")\n    cs = json.loads(get_customer_support_secret())\n    cleanup_cognito_resources(cs['pool_id'])\n    print(\"  ‚úÖ Cognito resources cleaned up\")\n    \n    print(\"  üóëÔ∏è  Deleting customer support secret...\")\n    delete_customer_support_secret()\n    print(\"  ‚úÖ Customer support secret deleted\")\n    \nexcept Exception as e:\n    print(f\"  ‚ö†Ô∏è  Error during security cleanup: {e}\")"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html#step-6-clean-up-local-files",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html#step-6-clean-up-local-files",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "Step 6: Clean Up Local Files",
    "text": "Step 6: Clean Up Local Files\nRemove generated configuration and code files from the local directory.\n\nprint(\"üìÅ Starting Local Files cleanup...\")\nlocal_file_cleanup()"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html#step-7-clean-up-observability-resources",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html#step-7-clean-up-observability-resources",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "Step 7: Clean Up Observability Resources",
    "text": "Step 7: Clean Up Observability Resources\nRemove CloudWatch log groups and streams used for agent monitoring.\n\nprint(\"üìä Starting Observability cleanup...\")\n\ndelete_observability_resources()"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-06-cleanup.html#cleanup-complete",
    "href": "code_files/aws_agentcore/lab-06-cleanup.html#cleanup-complete",
    "title": "üßπ AgentCore End-to-End Cleanup",
    "section": "üéâ Cleanup Complete!",
    "text": "üéâ Cleanup Complete!\nAll AgentCore resources have been cleaned up. Here‚Äôs a summary of what was removed:\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"üßπ CLEANUP COMPLETED SUCCESSFULLY! üßπ\")\nprint(\"=\" * 60)\nprint()\nprint(\"üìã Resources cleaned up:\")\nprint(\"  üß† Memory: AgentCore Memory resources and data\")\nprint(\"  üöÄ Runtime: Agent runtime and ECR repository\")\nprint(\"  üõ°Ô∏è Security: Roles, and SSM secrets\")\nprint(\"  üìä Observability: CloudWatch logs\")\nprint(\"  üìÅ Files: Local configuration files\")\nprint()\nprint(\"‚ú® Your AWS account is now clean and ready for new experiments!\")\nprint(\"\\nThank you for completing the AgentCore End-to-End tutorial! üöÄ\")"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-05-frontend.html",
    "href": "code_files/aws_agentcore/lab-05-frontend.html",
    "title": "Lab 5: Building a Customer-Facing Frontend Application",
    "section": "",
    "text": "In the previous labs, we‚Äôve built a comprehensive Customer Support Agent with memory, shared tools, and production-grade deployment. With them we show cased the capabilities of AgentCore services to move an agentic use case from prototype to production. You can now invoke your agent runtime from any application. On real world applications, customers expect an user interface to be available. Now it‚Äôs time to create a user-friendly frontend that customers can actually use to interact with our agent.\nWorkshop Journey: - Lab 1 (Done): Create Agent Prototype - Built a functional customer support agent - Lab 2 (Done): Enhance with Memory - Added conversation context and personalization - Lab 3 (Done): Scale with Gateway & Identity - Shared tools across agents securely - Lab 4 (Done): Deploy to Production - Used AgentCore Runtime with observability - Lab 5 (Current): Build User Interface - Create a customer-facing application\nIn this lab, we‚Äôll create a Streamlit-based web application that provides customers with an intuitive chat interface to interact with our deployed Customer Support Agent. The frontend will include:\n\nSecure Authentication - User login via Amazon Cognito\nReal-time Chat Interface - Streamlit-powered conversational UI\nStreaming Responses - Live response streaming for better user experience\nSession Management - Persistent conversations with memory\nResponse Timing - Performance metrics for transparency\n\n\n\nOur frontend application connects to the AgentCore Runtime endpoint we deployed in Lab 4, providing a complete end-to-end customer support solution:\n\n&lt;img src=\"images/architecture_lab5_streamlit.png\" width=\"100%\"/&gt;\n\n\n\n\n\nHow to integrate Secure Authentication with a frontend.\nHow to implement real-time streaming responses\nHow to manage user sessions and conversation context\nHow to create an intuitive chat interface for customer support\n\n\n\n\nBy the end of this lab, you will have:\n\nDeployed a customer-facing Streamlit web application\nIntegrated secure user authentication with AgentCore Identity\nImplemented real-time streaming chat responses\nCreated a complete end-to-end customer support solution\nTested the full customer journey from login to support resolution"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-05-frontend.html#overview",
    "href": "code_files/aws_agentcore/lab-05-frontend.html#overview",
    "title": "Lab 5: Building a Customer-Facing Frontend Application",
    "section": "",
    "text": "In the previous labs, we‚Äôve built a comprehensive Customer Support Agent with memory, shared tools, and production-grade deployment. With them we show cased the capabilities of AgentCore services to move an agentic use case from prototype to production. You can now invoke your agent runtime from any application. On real world applications, customers expect an user interface to be available. Now it‚Äôs time to create a user-friendly frontend that customers can actually use to interact with our agent.\nWorkshop Journey: - Lab 1 (Done): Create Agent Prototype - Built a functional customer support agent - Lab 2 (Done): Enhance with Memory - Added conversation context and personalization - Lab 3 (Done): Scale with Gateway & Identity - Shared tools across agents securely - Lab 4 (Done): Deploy to Production - Used AgentCore Runtime with observability - Lab 5 (Current): Build User Interface - Create a customer-facing application\nIn this lab, we‚Äôll create a Streamlit-based web application that provides customers with an intuitive chat interface to interact with our deployed Customer Support Agent. The frontend will include:\n\nSecure Authentication - User login via Amazon Cognito\nReal-time Chat Interface - Streamlit-powered conversational UI\nStreaming Responses - Live response streaming for better user experience\nSession Management - Persistent conversations with memory\nResponse Timing - Performance metrics for transparency\n\n\n\nOur frontend application connects to the AgentCore Runtime endpoint we deployed in Lab 4, providing a complete end-to-end customer support solution:\n\n&lt;img src=\"images/architecture_lab5_streamlit.png\" width=\"100%\"/&gt;\n\n\n\n\n\nHow to integrate Secure Authentication with a frontend.\nHow to implement real-time streaming responses\nHow to manage user sessions and conversation context\nHow to create an intuitive chat interface for customer support\n\n\n\n\nBy the end of this lab, you will have:\n\nDeployed a customer-facing Streamlit web application\nIntegrated secure user authentication with AgentCore Identity\nImplemented real-time streaming chat responses\nCreated a complete end-to-end customer support solution\nTested the full customer journey from login to support resolution"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-05-frontend.html#prerequisites",
    "href": "code_files/aws_agentcore/lab-05-frontend.html#prerequisites",
    "title": "Lab 5: Building a Customer-Facing Frontend Application",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nCompleted Labs 1-4\nPython 3.10+ installed locally\nStreamlit and required frontend dependencies\nAgentCore Runtime endpoint from Lab 4 (deployed and ready)\nAmazon Cognito user pool configured for authentication\n\n\nStep 1: Install Frontend Dependencies\nFirst, let‚Äôs install the required packages for our Streamlit frontend application.\n\n# Install frontend-specific dependencies\n%pip install -r lab_helpers/lab5_frontend/requirements.txt -q\nprint(\"‚úÖ Frontend dependencies installed successfully!\")\n\n\n\nStep 2: Understanding the Frontend Architecture\nOur Streamlit application consists of several key components:\n\nCore Components:\n\nmain.py - Main Streamlit application with UI and authentication\nchat.py - Chat management and AgentCore Runtime integration\nchat_utils.py - Utility functions for message formatting and display\nsagemaker_helper.py - Helper for generating accessible URLs\n\n\n\nAuthentication Flow:\n\nUser accesses the Streamlit application\nAmazon Cognito handles user authentication\nValid JWT tokens are used to authorize AgentCore Runtime requests\nUser can interact with the Customer Support Agent securely\n\n\n\n\nStep 3: Launch the Customer Support Frontend üöÄ\nNow let‚Äôs start our Streamlit application. The application will:\n\nGenerate an accessible URL for the application\nStart the Streamlit server on port 8501\nConnect to your deployed AgentCore Runtime from Lab 4\nProvide a complete customer support interface\n\nImportant Notes: - The application will run continuously until you stop it (Ctrl+C) - Make sure your AgentCore Runtime from Lab 4 is still deployed and running - The Cognito authentication tokens are valid for 2 hours\n\n# Get the accessible URL for the Streamlit application\nfrom lab_helpers.lab5_frontend.sagemaker_helper import get_streamlit_url\n\nstreamlit_url = get_streamlit_url()\nprint(f'\\nüöÄ Customer Support Streamlit Application URL:\\n{streamlit_url}\\n')\n\n# Start the Streamlit application\n!cd lab_helpers/lab5_frontend/ && streamlit run main.py\n\n\n\nStep 4: Testing Your Customer Support Application\nOnce your Streamlit application is running, you can test the complete customer support experience:\n\nAuthentication Testing:\n\nAccess the application using the Customer Support Streamlit Application URL provided above\nSign in with the test credentials provided in the output\nVerify that you see the welcome message with your username\n\n\n&lt;img src=\"images/lab5_streamlit_login.png\"/&gt;\n\n\n&lt;img src=\"images/lab5_welcome_user.png\"/&gt;\n\n\n\nCustomer Support Scenarios to Test:\nProduct Information Queries: ‚ÄúWhat are the specifications for your laptops?‚Äù\nReturn Policy Questions: ‚ÄúWhat‚Äôs the return policy for electronics?‚Äù\nTroubleshooting Support: ‚ÄúMy iPhone is overheating, what should I do?‚Äù\n\n&lt;img src=\"images/lab5_agent_question.png\" width=\"75%\"/&gt;\n\nMemory and Personalization Testing: Have a conversation, then refresh the page\n\n&lt;img src=\"images/lab5_agent_chat_history.png\" width=\"75%\"/&gt;\n\n\n\nWhat to Observe:\n\nReal-time streaming - Responses appear as they‚Äôre generated\nResponse timing - Performance metrics displayed with each response\nMemory persistence - Agent remembers conversation context\nTool integration - Agent uses appropriate tools for different queries\nProfessional UI - Clean, intuitive customer support interface\nError handling - Graceful handling of any issues"
  },
  {
    "objectID": "code_files/aws_agentcore/lab-05-frontend.html#lab-5-complete",
    "href": "code_files/aws_agentcore/lab-05-frontend.html#lab-5-complete",
    "title": "Lab 5: Building a Customer-Facing Frontend Application",
    "section": "üéâ Lab 5 Complete!",
    "text": "üéâ Lab 5 Complete!\nCongratulations! You‚Äôve successfully built and deployed a complete customer-facing frontend application for your AI-powered Customer Support Agent. Here‚Äôs what you accomplished:\n\nWhat You Built\n\nWeb Interface - Streamlit-based customer support application\nSecure Authentication - Amazon Cognito integration for user management\nReal-time Streaming - Live response streaming for better user experience\nSession Management - Persistent conversations with memory across interactions\nComplete Integration - Frontend connected to your AgentCore Runtime\n\n\n\nEnd-to-End Customer Support Solution\nYou now have a complete, customer support system that includes:\n\nIntelligent Agent (Lab 1) - AI-powered support with custom tools\nPersistent Memory (Lab 2) - Conversation context and personalization\nShared Tools & Identity (Lab 3) - Scalable tool sharing and access control\nProduction Runtime (Lab 4) - Secure, scalable deployment with observability\nCustomer Frontend (Lab 5) - web interface for end users\n\n\n\nKey Capabilities Demonstrated\n\nMulti-turn Conversations - Agent maintains context across interactions\nTool Integration - Seamless use of product info, return policy, and web search\nMemory Persistence - Customer preferences and history maintained\nReal-time Performance - Streaming responses with performance metrics\nSecurity & Identity - Proper authentication and authorization\nObservability - Full tracing and monitoring of agent behavior\n\n\n\nNext Steps\nTo further enhance your customer support solution, consider:\n\nCustom Styling - Brand the frontend with your company‚Äôs design system\nAdditional Tools - Integrate with your existing CRM, ticketing, or knowledge base systems\nMulti-language Support - Add internationalization for global customers\nAdvanced Analytics - Implement custom dashboards for support team insights\nMobile Optimization - Ensure the interface works well on mobile devices\n\n\n\nCleanup\nWhen you‚Äôre ready to clean up the resources created in this workshop:\nReady to clean up? Proceed to Lab 6: Cleanup ‚Üí\n\nüéä Congratulations on completing the Amazon Bedrock AgentCore End-to-End Workshop!\nYou‚Äôve successfully built a complete, production-ready AI agent solution from prototype to customer-facing application using Amazon Bedrock AgentCore capabilities."
  },
  {
    "objectID": "index.html#tools-of-the-trade",
    "href": "index.html#tools-of-the-trade",
    "title": "Aarushi Nema",
    "section": "Tools of the Trade",
    "text": "Tools of the Trade\n\n  \n    \n      \n      Data / AI\n      I specialize in building scalable data pipelines and intelligent systems, combining machine learning, deep learning, and responsible AI research. My experience spans data migration with PySpark and Airflow at Hyundai, ETL automation and RPA development at Infineon, and academic projects including conversational recommender systems (PRICAI 2025 accepted), value-aligned LLMs (NeurIPS 2025 submission), and a top 3.2% Kaggle solution using LightGBM ensembles.\n      Tech stack:\n      \n        Python\n        PyTorch\n        TensorFlow\n        Scikit-Learn\n        PySpark\n        Hadoop\n        SQL\n        Tableau\n        Pandas\n      \n    \n\n    \n      \n      Web/Mobile dev\n      I have built full-stack applications that integrate APIs, databases, and modern frameworks to deliver seamless user experiences. My work includes Flask APIs for Hadoop data retrieval at Hyundai, a React‚ÄìFlask‚ÄìSQL chatbot at Infineon, a React Native mobile app with Node.js and MongoDB Atlas under Credit Suisse mentorship, and NTU Student Union portals redesigned with ReactJS, Tailwind, and Django APIs to improve usability and performance.\n      Tech stack:\n      \n        Flask\n        Django\n        ReactJS\n        React Native\n        NodeJS\n        MongoDB\n        JavaScript\n        Quarto\n      \n    \n\n  \n\n  \n     \n      \n      CI/CD & Automation\n      I have developed feature-rich Android applications using Kotlin and Java, with hands-on experience in Android Studio and a solid understanding of app lifecycle management.\n      Tech stack:\n      \n        Kotlin\n        Java\n        Flutter\n        Android Studio\n        Firebase\n      \n    \n\n     \n      \n      UI/UX\n      I have developed feature-rich Android applications using Kotlin and Java, with hands-on experience in Android Studio and a solid understanding of app lifecycle management.\n      Tech stack:\n      \n        Kotlin\n        Java\n        Flutter\n        Android Studio\n        Firebase"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Aarushi Nema",
    "section": "Experience",
    "text": "Experience\n\n  \n    \n      \n        Data Platform Intern\n        Hyundai Motor Group Innovation Centre Singapore\n      \n      \n        May 2024 ‚Äì Aug 2024\n      \n    \n    \n      \n        Engineered and optimized scalable data migration pipelines from Relational DBMS (PostgreSQL and Tibero) to Hadoop Data Lake using Python, PySpark, Apache Airflow, and Bash scripting\n        Developed RESTful APIs using Flask and PySpark to enable dynamic data retrieval and filtering from Hadoop Data Lake across multiple data formats\n        Designed and implemented a dynamic data synchronization pipeline integrating multiple database systems to PostgreSQL using PySpark, ensuring data consistency and reliability\n        Created technical documentation for data pipelines\n      \n    \n  \n\n  \n    \n      \n        Software Development (Data Application) Intern\n        Infineon Technologies\n      \n      \n        May 2023 ‚Äì Dec 2023\n      \n    \n    \n      \n        Collaborated closely with stakeholders and product engineers to identify data challenges and translate business requirements into robust data engineering solutions, resulting in enhanced Tableau dashboards and optimized data pipelines with new feature integrations\n        Developed Python scripts to automate extraction, transformation, and loading (ETL) process for production yield records into a SQL database using Jenkins, meeting stakeholder specifications, and creating an automated email notification system based on the data\n        Spearheaded development of a centralized Robotic Process Automation (RPA) solution from scratch utilizing UiPath and Python, resulting in an 90% reduction in human intervention across four critical software tools\n        Designed and implemented a Confluence-based chatbot using React, Flask, and SQL, significantly reducing time spent searching for and navigating through various software tools\n        Presented technical projects and dashboards to cross-functional teams, translating complex data workflows into business impact"
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Aarushi Nema",
    "section": "Projects",
    "text": "Projects\n\n  \n    \n      \n        \n      \n      \n        Power of SVM\n        Small demo building a linear SVM for classification with clear visualizations.\n        Read more\n      \n    \n    \n    \n      \n        \n      \n      \n        CSS Magic\n        Design exploration: building crisp, modern components with minimal CSS.\n        See design\n      \n    \n    \n    \n      \n        \n      \n      \n        Round Up App\n        UI/UX design for a financial app that helps users save money through round-up features.\n        View project\n      \n    \n    \n    \n      \n        \n      \n      \n        AI Agent Core\n        Building a comprehensive customer support agent using Amazon BedRock AgentCore.\n        Read more\n      \n    \n    \n    \n      \n        \n      \n      \n        Art Portfolio\n        Collection of digital sketches and illustrations showcasing creative design skills.\n        View gallery\n      \n    \n    \n    \n      \n        \n      \n      \n        Portfolio Website\n        Personal portfolio website built with Quarto, featuring responsive design and modern aesthetics.\n        Explore site\n      \n    \n  \n\n\nContact\n\n‚úâÔ∏è aarushi.nema02@gmail.com\n\nüîó LinkedIn\n\nüêô GitHub"
  },
  {
    "objectID": "design_portfolio.html",
    "href": "design_portfolio.html",
    "title": "Design Portfolio",
    "section": "",
    "text": "RoundUp: Finance Tracking App\n\n\n\n\n\n\n\n\nFeb 22, 2023\n\n\nAarushi Nema\n\n\n\n\n\nNo matching items"
  }
]